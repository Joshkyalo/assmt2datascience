{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b55559-03ec-4b0a-a616-bce1d65ab78a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1 style=\"color:#ffc0cb;font-size:40px;font-family:Georgia;text-align:center;\"><strong>Forming Hypotheses</strong></h1>\n",
    "\n",
    "+ What time of day and day of the week do most major incidents happen?\n",
    "+ Are there any patterns in the day, week, month, year when significant incidents occur?\n",
    "+ What characteristics stand out in significant incidents compared with other accidents?\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b25e80c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1 style=\"color:#ffc0cb;font-size:40px;font-family:Georgia;text-align:center;\"><strong>Table of Content</strong></h1>\n",
    "\n",
    "### 1. [OVERVIEW AND IMPORTING DATA](#1)\n",
    "\n",
    "1.1 [Overview](#1.1)\n",
    "\n",
    "1.2 [Required  Libraries](#1.2)\n",
    "\n",
    "<br>\n",
    "\n",
    "### 2. [Data Preparation & Data exploration (EDA)](#2)\n",
    "\n",
    "2.1 [Number of Accidents per State](#2.1)\n",
    "\n",
    "2.2 [Most frequent words in the description](#2.2)\n",
    "\n",
    "2.3 [Most frequent road features](#2.3)\n",
    "\n",
    "2.4 [Medium distance by severity](#2.4)\n",
    "\n",
    "2.5 [Weather condition histogram](#2.5)\n",
    "\n",
    "2.6 [Number of accidents for weekday](#2.6)\n",
    "\n",
    "<!-- \n",
    "2.1 [Number of Accidents per State](#2.1)\n",
    "\n",
    "2.2 [Most frequent words in the description](#2.2)\n",
    "\n",
    "2.3 [Most frequent road features](#2.3)\n",
    "\n",
    "2.4 [Medium distance by severity](#2.4)\n",
    "\n",
    "2.5 [Weather condition histogram](#2.5)\n",
    "\n",
    "2.6 [Number of accidents for weekday](#2.6) -->\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### 3. [Feature engineering](#3)\n",
    "    \n",
    "\n",
    "3.1 [Feature addition](#3.1)\n",
    "\n",
    "3.2 [Check correlation between features](#3.2)\n",
    "\n",
    "3.3 [Feature selection](#3.3)\n",
    "\n",
    "3.4 [Drop duplicates](#3.4)\n",
    "\n",
    "3.5 [Handle erroneous and missing values](#3.5)\n",
    "\n",
    "3.6 [Check features variance](#3.6)\n",
    "\n",
    "3.7 [Handle unbalanced data](#3.7)\n",
    "\n",
    "3.8 [Feature scaling](#3.8)\n",
    "\n",
    "3.9 [Feature encoding](#3.9)\n",
    "\n",
    "<br>\n",
    "\n",
    "### 4. [Model training](#4)\n",
    "\n",
    "4.1 [Logistic regression](#4.1)\n",
    "\n",
    "4.2 [Decision Tree](#4.2)\n",
    "\n",
    "4.3 [Random Forest](#4.3)\n",
    "\n",
    "<br>\n",
    "\n",
    "### 5. [Model evaluation and export](#5)\n",
    "\n",
    "<br>\n",
    "\n",
    "### 6. [References](#6)\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e99310b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T14:11:28.013292Z",
     "iopub.status.busy": "2021-10-13T14:11:28.01297Z",
     "iopub.status.idle": "2021-10-13T14:11:28.038758Z",
     "shell.execute_reply": "2021-10-13T14:11:28.036946Z",
     "shell.execute_reply.started": "2021-10-13T14:11:28.013264Z"
    },
    "papermill": {
     "duration": 0.075904,
     "end_time": "2021-10-14T09:56:52.253889",
     "exception": false,
     "start_time": "2021-10-14T09:56:52.177985",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1 style=\"color:#ffc0cb;font-size:40px;font-family:Georgia;text-align:center;\"><strong>1. Overview Dataset</strong></h1>\n",
    "\n",
    "<a id=\"1.1\"></a>\n",
    "# 1.1 Overview\n",
    "\n",
    "[Dataset Details](https://smoosavi.org/datasets/us_accidents)\n",
    "\n",
    "\n",
    "**Traffic Attributes (12)**:\n",
    "\n",
    "* **ID**: This is a unique identifier of the accident record.\n",
    "\n",
    "* **Severity**: Shows the severity of the accident, a number between 1 and 4, where 1 indicates the least impact on traffic (i.e., short delay as a result of the accident) and 4 indicates a significant impact on traffic (i.e., long delay).\n",
    "\n",
    "* **Start_Time**: Shows start time of the accident in local time zone.\n",
    "\n",
    "* **End_Time**: Shows end time of the accident in local time zone.\n",
    "\n",
    "* **Start_Lat**: Shows latitude in GPS coordinate of the start point.\n",
    "\n",
    "* **Start_Lng**: Shows longitude in GPS coordinate of the start point.\n",
    "\n",
    "* **End_Lat**: Shows latitude in GPS coordinate of the end point.\n",
    "\n",
    "* **End_Lng**: Shows longitude in GPS coordinate of the end point.\n",
    "\n",
    "* **Distance(mi)**: The length of the road extent affected by the accident.\n",
    "\n",
    "\n",
    "**Address Attributes (9)**:\n",
    "\n",
    "* **Number**: Shows the street number in address field.\n",
    "\n",
    "* **Street**: Shows the street name in address field.\n",
    "\n",
    "* **Side**: Shows the relative side of the street (Right/Left) in address field.\n",
    "\n",
    "* **City**: Shows the city in address field.\n",
    "\n",
    "* **County**: Shows the county in address field.\n",
    "\n",
    "* **State**: Shows the state in address field.\n",
    "\n",
    "* **Zipcode**: Shows the zipcode in address field.\n",
    "\n",
    "* **Country**: Shows the country in address field.\n",
    "\n",
    "* **Timezone**: Shows timezone based on the location of the accident (eastern, central, etc.).\n",
    "\n",
    "**Weather Attributes (11)**:\n",
    "\n",
    "* **Airport_Code**: Denotes an airport-based weather station which is the closest one to location of the accident.\n",
    "\n",
    "* **Weather_Timestamp**: Shows the time-stamp of weather observation record (in local time).\n",
    "\n",
    "* **Temperature(F)**: Shows the temperature (in Fahrenheit).\n",
    "\n",
    "* **Wind_Chill(F)**: Shows the wind chill (in Fahrenheit).\n",
    "\n",
    "* **Humidity(%)**: Shows the humidity (in percentage).\n",
    "\n",
    "* **Pressure(in)**: Shows the air pressure (in inches).\n",
    "\n",
    "* **Visibility(mi)**: Shows visibility (in miles).\n",
    "\n",
    "* **Wind_Direction**: Shows wind direction.\n",
    "\n",
    "* **Wind_Speed(mph)**: Shows wind speed (in miles per hour).\n",
    "\n",
    "* **Precipitation(in)**: Shows precipitation amount in inches, if there is any.\n",
    "\n",
    "* **Weather_Condition**: Shows the weather condition (rain, snow, thunderstorm, fog, etc.).\n",
    "\n",
    "**POI Attributes (13)**:\n",
    "\n",
    "* **Amenity**: A Point-Of-Interest (POI) annotation which indicates presence of amenity in a nearby location.\n",
    "\n",
    "* **Bump**: A POI annotation which indicates presence of speed bump or hump in a nearby location.\n",
    "\n",
    "* **Crossing**: A POI annotation which indicates presence of crossing in a nearby location.\n",
    "\n",
    "* **Give_Way**: A POI annotation which indicates presence of give_way sign in a nearby location.\n",
    "\n",
    "* **Junction**: A POI annotation which indicates presence of junction in a nearby location.\n",
    "\n",
    "* **No_Exit**: A POI annotation which indicates presence of no_exit sign in a nearby location.\n",
    "\n",
    "* **Railway**: A POI annotation which indicates presence of railway in a nearby location.\n",
    "\n",
    "* **Roundabout**: A POI annotation which indicates presence of roundabout in a nearby location.\n",
    "\n",
    "* **Station**: A POI annotation which indicates presence of station (bus, train, etc.) in a nearby location.\n",
    "\n",
    "* **Stop**: A POI annotation which indicates presence of stop sign in a nearby location.\n",
    "\n",
    "* **Traffic_Calming**: A POI annotation which indicates presence of traffic_calming means in a nearby location.\n",
    "\n",
    "* **Traffic_Signal**: A POI annotation which indicates presence of traffic_signal in a nearby location.\n",
    "\n",
    "* **Turning_Loop**: A POI annotation which indicates presence of turning_loop in a nearby location.\n",
    "\n",
    "**Period-of-Day (4)**:\n",
    "\n",
    "* **Sunrise_Sunset**: Shows the period of day (i.e. day or night) based on sunrise/sunset.\n",
    "\n",
    "* **Civil_Twilight**: Shows the period of day (i.e. day or night) based on civil twilight.\n",
    "\n",
    "* **Nautical_Twilight**: Shows the period of day (i.e. day or night) based on nautical twilight.\n",
    "\n",
    "* **Astronomical_Twilight**: Shows the period of day (i.e. day or night) based on astronomical twilight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1379f034-9026-47bb-a5f6-72650f2a0640",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"1.2\"></a>\n",
    "# 1.2 Required  Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67d5707-0107-4126-892c-f9ebbe47fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a conda package in the current Jupyter kernel\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} missingno\n",
    "\n",
    "# work with data in tabular representation\n",
    "from datetime import time\n",
    "\n",
    "import pandas as pd\n",
    "# round the data in the correlation matrix\n",
    "import numpy as np\n",
    "# module for regular expression\n",
    "import re\n",
    "\n",
    "# Modules for data visualization\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "from scipy.stats import skew  # for some statistics\n",
    "import matplotlib.style as style\n",
    "from xgboost import sklearn\n",
    "import statsmodels.api as sm\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [6, 6]\n",
    "\n",
    "# Ensure that our plots are shown and embedded within the Jupyter notebook itself. Without this command, sometimes plots may show up in pop-up windows\n",
    "%matplotlib inline\n",
    "\n",
    "# run a python file \n",
    "%run function.py\n",
    "\n",
    "# overwrite the style of all the matplotlib graphs\n",
    "sns.set()\n",
    "\n",
    "# ignore DeprecationWarning Eror Messages\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77672d9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "# check the version of the package\n",
    "print(sklearn.__version__)\n",
    "print(np.__version__)\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad43651-bbb5-4bb8-8770-e51314fa37d8",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<h1 style=\"color:#ffc0cb;font-size:40px;font-family:Georgia;text-align:center;\"><strong>2. Data Preparation & Data exploration (EDA)</strong></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e069772-f358-48b0-9473-549d29ed54ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"2.1\"></a>\n",
    "# 2.1 Data Preparation\n",
    "\n",
    "Perform all necessary data cleaning and preparation for train, test, validation\n",
    "\n",
    "[Detail of the dataset](https://smoosavi.org/datasets/us_accidents)\n",
    "\n",
    "#### Original Memory usage of each dataset\n",
    "+ TRAIN: memory usage: 120.1+ MB\n",
    "+ TEST: memory usage: 40.0+ MB\n",
    "+ VALIDATION: memory usage: 40.0+ MB\n",
    "\n",
    "#### Understand the problem\n",
    "+ Data Type: Tabular data\n",
    "+ Problem Type:  Regression\n",
    "+ Evaludation Metric: RMSE, MSE, MAE, R2\n",
    "\n",
    "#### I drop `ResponseId` to avoid leakage of the data. \n",
    "The unique identifier of the accident record is not relevant for this problem. So I will omit it from all DataFrames and call the `info()` method to **check their high level information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab066a61-a6bc-4b05-a86b-459829bdbed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from function import style\n",
    "%time\n",
    "\n",
    "# TRAIN\n",
    "# read and drop drop ID column-wise\n",
    "# train = pd.read_csv('cosc2789-2021/train.csv', parse_dates=['End_Time', 'Start_Time', 'Weather_Timestamp']).drop(\"ID\", axis=1)\n",
    "train = pd.read_csv('cosc2789-2021/train.csv').drop(\"ID\", axis=1)\n",
    "# method to find the number of columns is to use .shape, which prints out the full dimensions of the data:\n",
    "print(f'The TRAIN Dataframe contain {train.shape[0]} records and {train.shape[1]} columns.\\n\\n')  # 454819 rows and 45 columns\n",
    "# lets make end time as index\n",
    "train = train.sort_values(by=['End_Time'])\n",
    "# use the .info() method, which will print out a concise summary of the DataFrame:\n",
    "print(train.info())\n",
    "print('--------------------------------------------------------------------------')\n",
    "# print out first 3 lines of the dataframe\n",
    "# style(train.head(3))\n",
    "\n",
    "\n",
    "# VALIDATION\n",
    "# read and drop drop ID column-wise\n",
    "validation = pd.read_csv('cosc2789-2021/val.csv').drop(\"ID\", axis=1)\n",
    "# method to find the number of columns is to use .shape, which prints out the full dimensions of the data:\n",
    "print(f'The VALIDATION Dataframe contain {validation.shape[0]} records and {validation.shape[1]} columns.\\n\\n')  # 151606 rows and 45 columns\n",
    "# lets make end time as index\n",
    "validation = validation.sort_values(by=['End_Time'])\n",
    "# use the .info() method, which will print out a concise summary of the DataFrame:\n",
    "print(validation.info())\n",
    "print('--------------------------------------------------------------------------')\n",
    "# print out first 3 lines of the dataframe\n",
    "# style(validation.head(3))\n",
    "\n",
    "\n",
    "# TRAIN\n",
    "# read and drop drop ID column-wise\n",
    "test = pd.read_csv('cosc2789-2021/test.csv')\n",
    "# method to find the number of columns is to use .shape, which prints out the full dimensions of the data:\n",
    "print(f'The TEST Dataframe contain {test.shape[0]} records and {test.shape[1]} columns.\\n\\n')  # 151607 rows and 44 columns\n",
    "# lets make end time as index\n",
    "# use the .info() method, which will print out a concise summary of the DataFrame:\n",
    "print(test.info())\n",
    "print('--------------------------------------------------------------------------')\n",
    "# print out first 3 lines of the dataframe\n",
    "style(test.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4020dfa2-adc3-4003-a582-4bc259f911f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ---------------> OBSERVATION\n",
    "<hr>\n",
    "\n",
    "> The TRAIN Dataframe contain 454819 records and 45 columns.\n",
    "There are  454819 training examples in the dataset, this is a good sign since there seems to be large enough data for machine learning. The shape of the dataset tells is that I have 45 attributes. Of the 45 attributes, one is the target variable that the model should predict. This means that I have 44 attributes that have the potential to be used to train my future predictive model.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addca98d-b609-4d11-95c6-43bd177ccc60",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br><br>\n",
    "<a id=\"2.2\"></a>\n",
    "# Task 2.2: Check data types & Make the data homogeneous\n",
    "The dtypes that pandas uses are: `float`, `int`, `bool`, `datetime`, `timedelta`, `category` and `object`. I modify data types in my DataFrames to help me transform them into more meaningful metrics\n",
    "\n",
    "+ Cast pandas objects to a specified dtype dtype (string)¶\n",
    "+ Numeric data should have for example the same number of digits after the point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0945930c-292f-4c81-ada4-7976abd98f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert columns to the best possible dtypes, object->string\n",
    "train = train.convert_dtypes()\n",
    "test = test.convert_dtypes()\n",
    "validation = validation.convert_dtypes()\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abf6fe4-4eae-4d73-9e61-d50560263859",
   "metadata": {},
   "source": [
    "## --------> OBSERVATION\n",
    "\n",
    "<hr>\n",
    "\n",
    "> The method `.info()` is great for checking out the data types of the different features already coverted into the desired types and non-null values. However, it is not great for getting a visual picture of what is missing for the different features. You will use missingno for this\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1be158-c735-4a02-98f5-732f2477f0d7",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<a id=\"2.3\"></a>\n",
    "# 2.3 Missing Values\n",
    "<a id=\"2.3.1\"></a>\n",
    "### 2.3.1 Guess the missingness type \n",
    "\n",
    "#### 3 types of missingness patterns:\n",
    "+ Missing completely at Random (MCAR)\n",
    "+ Missing at Random (MAR)\n",
    "+ Missing Not at Random (MNAR)\n",
    "\n",
    "> I'll first visualize the missingness summary and then identify the types of missingness the DataFrame contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61e5fc4-8719-4ab8-b248-4735099e83ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from function import missing_percentage\n",
    "\n",
    "# display missing values in descending\n",
    "print(\"Missing values in TRAIN in ascending: \\n\", missing_percentage(train))\n",
    "\n",
    "# visualize where the missing values are located\n",
    "msno.matrix(test, color=(255 / 255, 192 / 255, 203 / 255))\n",
    "pink_patch = mpatches.Patch(color='pink', label='present value')\n",
    "white_patch = mpatches.Patch(color='white', label='absent value')\n",
    "plt.legend(handles=[pink_patch, white_patch])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f510d-450f-4704-a7e9-c2c61f1658e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display missing values in descending\n",
    "print(\"Missing values in TEST in ascending: \\n\", missing_percentage(test))\n",
    "\n",
    "# visualize where the missing values are located\n",
    "msno.matrix(test, color=(255 / 255, 192 / 255, 203 / 255))\n",
    "pink_patch = mpatches.Patch(color='pink', label='present value')\n",
    "white_patch = mpatches.Patch(color='white', label='absent value')\n",
    "plt.legend(handles=[pink_patch, white_patch])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a72ccf-6a89-4103-a3ea-815936f18d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display missing values in descending\n",
    "print(\"Missing values in VALIDATION in ascending: \\n\", missing_percentage(validation))\n",
    "\n",
    "# visualize where the missing values are located\n",
    "msno.matrix(validation, color=(255 / 255, 192 / 255, 203 / 255))\n",
    "pink_patch = mpatches.Patch(color='pink', label='present value')\n",
    "white_patch = mpatches.Patch(color='white', label='absent value')\n",
    "plt.legend(handles=[pink_patch, white_patch])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0286427e-c2a4-447a-a81e-7850b117dd0e",
   "metadata": {},
   "source": [
    "### ------> OBSERVATION\n",
    "\n",
    "<hr>\n",
    "\n",
    "+ Only a few missing values of the dataframes suggests that it MIGHT be missing completely at random due to a small number oif missingness\n",
    "\n",
    "> Sunrise_Sunset: 3\n",
    "\n",
    "> Civil_Twilight: 3\n",
    "\n",
    "> Nautical_Twilight: 3\n",
    "\n",
    "> Astronomical_Twilight: 3\n",
    "\n",
    "> City: 3\n",
    "\n",
    "### --> I'm going to delete any missing column that has IS COMPLETELY AT RANDOM (MCAR) AND the number of missing values is VERY SMALL\n",
    "+ There is a strong correlation the strong correlation between `Number`, `Wind Chill(F)` and `Precipitation(in)`.  \n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcf6b56-51f8-4d43-9b88-34ad258b8c5b",
   "metadata": {},
   "source": [
    "<a id=\"2.3.2\"></a>\n",
    "### 2.3.2 Drop missing values pairwise for train and validation set by deleting their rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651aa5a-a3ca-4dbc-a729-b5f57eb43aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise delete the rows \n",
    "train.dropna(subset=['Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight', 'City'], how='any', inplace=True)\n",
    "\n",
    "validation.dropna(subset=['Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight', 'City'], how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be328d2d-91ff-428d-97ae-7468c62f7bbd",
   "metadata": {},
   "source": [
    "<a id=\"2.3.3\"></a>\n",
    "### 2.3.3 Drop missing values listwise for all the datasets by deleting their columns\n",
    "\n",
    "+ `Street` Shows the street number in address field which too specific for the prediction and have too much missing values (>60%).\n",
    "\n",
    "+ `Country` shows the dataset is about accidents happening in the United States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d26394d-c1d8-4675-a543-905c9276d433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out list of country types \n",
    "print(\"Number of categories in Country column - TRAIN:\", train.Country.nunique())\n",
    "print(\"Categories in TRAIN:\", train.Country.unique())\n",
    "\n",
    "print(\"Number of categories in Country column - TEST:\", test.Country.nunique())\n",
    "print(\"Categories in TEST:\", test.Country.unique())\n",
    "\n",
    "print(\"Number of categories in Country column - VALIDATION:\", validation.Country.nunique())\n",
    "print(\"Categories in VALIDATION:\", validation.Country.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2494b2fd-0385-40d7-ba73-8c12d5e4d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out list of Turning_Loop types \n",
    "print(\"Number of categories:\", train.Turning_Loop.nunique())\n",
    "print(\"Categories:\", train.Turning_Loop.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655e19c7-471e-4963-ad17-898cea8a78e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out list of Street types \n",
    "print(f'NUMBER OF CATEGORIES: {train.Street.nunique()}; \\nUNIQUE NAMES OF THE CATEGORIES {train.Street.unique()}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a50ed35-97fe-4191-9ffd-afbfa1b9e155",
   "metadata": {},
   "source": [
    "### ----------> OBSERVAITON:\n",
    "\n",
    "<hr>\n",
    "\n",
    "> Remove the `Country` and `Turning_Loop` have a constant value with single categorical value that can be dropped becasue I couldn't compute the covariance with them\n",
    "\n",
    "> `Number` has 64% of missing data and too much missing values (>60%) can be removed as this would not be used for analysis. \n",
    "\n",
    "> `Street` has 53871 unique values which is not meaningful for my further model prediction\n",
    "\n",
    "> `Precipitation(in)` has 57% of missing data but this one is a key factor for rain/snow so can be recovered with these feature columns but the preciptation must be changed to categorical value. \n",
    "\n",
    "> `Wind_Chill(F)` the percentage of missing data is 53%, considering the fact of this feature, this can also be removed.\n",
    "\n",
    "> `Street` shows the street number in address field which too specific for the prediction and have.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c01180-c0ac-49a0-b96e-a5cd11b16d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop listwise columns for all datasets\n",
    "train = train.drop(labels=['Street', 'Turning_Loop', 'Country', 'Number', 'Wind_Chill(F)'], axis=1)\n",
    "test = test.drop(labels=['Street', 'Turning_Loop', 'Country', 'Number', 'Wind_Chill(F)'], axis=1)\n",
    "validation = validation.drop(labels=['Street', 'Turning_Loop', 'Country', 'Number', 'Wind_Chill(F)'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c27c9a-316c-4d29-a135-da777191586e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"2.3.4\"></a>\n",
    "### 2.3.4 [Interpolate() - Nearest Value imputation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.interpolate.html)\n",
    "\n",
    "+ I've sorted all data frames by their `End_Time`, now I only need to fill `na` based on the corresponding `Weather_Timestamp` in the previous row. \n",
    "\n",
    "+ I could not sort the test data set by the `End_time` since it would mess up my Kaggle result. Moreover, `Weather_Timestamp` approximately equal to `Start_Time` and `Start_Time` has no missing value; I'll fill na in `Weather_Timestamp` with `Start_Time` in the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3200a32-c553-4af3-b8f3-15545c6d084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate the NaNs with nearest value for Weather_Timestamp column\n",
    "train.Weather_Timestamp.interpolate(method='ffill', inplace=True)\n",
    "test['Weather_Timestamp'] = test['Weather_Timestamp'].fillna(test['Start_Time'])\n",
    "validation.Weather_Timestamp.interpolate(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a4f8f0-9cd6-4d93-885d-bddf45316975",
   "metadata": {},
   "source": [
    "<a id=\"2.3.5\"></a>\n",
    "### 2.3.5 Median & Frequent Categorical Imputation for Weather Continuous features\n",
    "\n",
    "Continuous weather features with missing values:\n",
    "\n",
    "1. Temperature(F)\n",
    "\n",
    "2. Humidity(%)\n",
    "\n",
    "3. Pressure(in)\n",
    "\n",
    "4. Visibility(mi)\n",
    "\n",
    "5. Wind_Speed(mph)\n",
    "\n",
    "`apply` + `pd.to_numeric` + `mask` + `fillna`\n",
    "\n",
    "**According to the [A Countrywide Traffic Accident Dataset](https://arxiv.org/abs/1906.05409):**\n",
    "\"Weather Underground API to obtain weather information for each accident. Raw weather data was collected from 1,977 **weather stations located in airports** all around the United States.\"\n",
    "\n",
    "+ Grouped by location and time. 'Airport_Code' is selected as a location feature because the sources of weather data are airport-based weather stations. \n",
    "\n",
    "+ Then, the data will be grouped by 'Start_Month' rather than 'Start_Hour' because using the former is computationally cheaper and remains less missing values. Finally, missing values will be replaced by a median value of each group. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae959dd-57a1-45c0-9081-8db9a27c0af9",
   "metadata": {},
   "source": [
    "### Splitting up the timming in all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d9b20-bd13-43d3-aaa1-da7d69352c2f",
   "metadata": {
    "id": "0W4CubmvSobC"
   },
   "outputs": [],
   "source": [
    "# slice the column to get the year, month, date\n",
    "def get_years(df, column):\n",
    "    return df[column].apply(lambda date: date[0:4])\n",
    "\n",
    "def get_months(df, column):\n",
    "    return df[column].apply(lambda date: date[5:7])\n",
    "\n",
    "def get_hours(df, column):\n",
    "    return df[column].apply(lambda date: date[11:13])\n",
    "\n",
    "\n",
    "# TRAIN\n",
    "train['Start_Time_Month'] = get_months(train, 'Start_Time')\n",
    "train['Start_Time_Year'] = get_years(train, 'Start_Time')\n",
    "train['Start_Time_Hour'] = get_hours(train, 'Start_Time')\n",
    "\n",
    "train['End_Time_Month'] = get_months(train, 'End_Time')\n",
    "train['End_Time_Year'] = get_years(train, 'End_Time')\n",
    "train['End_Time_Hour'] = get_hours(train, 'End_Time')\n",
    "\n",
    "train['Weather_Timestamp_Month'] = get_months(train, 'Weather_Timestamp')\n",
    "train['Weather_Timestamp_Year'] = get_years(train, 'Weather_Timestamp')\n",
    "train['Weather_Time_Hour'] = get_hours(train, 'Weather_Timestamp')\n",
    "\n",
    "# TEST\n",
    "test['Start_Time_Month'] = get_months(test, 'Start_Time')\n",
    "test['Start_Time_Year'] = get_years(test, 'Start_Time')\n",
    "test['Start_Time_Hour'] = get_hours(test, 'Start_Time')\n",
    "\n",
    "test['End_Time_Month'] = get_months(test, 'End_Time')\n",
    "test['End_Time_Year'] = get_years(test, 'End_Time')\n",
    "test['End_Time_Hour'] = get_hours(test, 'End_Time')\n",
    "\n",
    "test['Weather_Timestamp_Month'] = get_months(test, 'Weather_Timestamp')\n",
    "test['Weather_Timestamp_Year'] = get_years(test, 'Weather_Timestamp')\n",
    "test['Weather_Time_Hour'] = get_hours(test, 'Weather_Timestamp')\n",
    "\n",
    "# VALIDATION\n",
    "validation['Start_Time_Month'] = get_months(validation, 'Start_Time')\n",
    "validation['Start_Time_Year'] = get_years(validation, 'Start_Time')\n",
    "validation['Start_Time_Hour'] = get_hours(validation, 'Start_Time')\n",
    "\n",
    "validation['End_Time_Month'] = get_months(validation, 'End_Time')\n",
    "validation['End_Time_Year'] = get_years(validation, 'End_Time')\n",
    "validation['End_Time_Hour'] = get_hours(validation, 'End_Time')\n",
    "\n",
    "validation['Weather_Timestamp_Month'] = get_months(validation, 'Weather_Timestamp')\n",
    "validation['Weather_Timestamp_Year'] = get_years(validation, 'Weather_Timestamp')\n",
    "validation['Weather_Time_Hour'] = get_hours(validation, 'Weather_Timestamp')\n",
    "\n",
    "\n",
    "# Drop original colums\n",
    "train = train.drop(['Start_Time', 'End_Time', 'Weather_Timestamp'], axis=1)\n",
    "test = test.drop(['Start_Time', 'End_Time', 'Weather_Timestamp'], axis=1)\n",
    "validation = validation.drop(['Start_Time', 'End_Time', 'Weather_Timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b0e36-10e9-44cf-b72e-d66bb1e2defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bdaca0-a063-4783-a2e5-fc0b3130664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "from collections import Counter\n",
    "\n",
    "def fill_mode_wind_direction(df):\n",
    "    # grouping data to fill NAs with majority value\n",
    "    df['Wind_Direction'] = df.groupby(['Airport_Code', 'Start_Time_Year', 'Start_Time_Month', 'Start_Time_Hour'])['Wind_Direction'].apply(\n",
    "        lambda x: x.fillna(Counter(x).most_common()[0][0]) if all(x.isnull()) == False else x)\n",
    "    print('Wind_Direction' + \" fill type 1 for Nan : \" + df['Wind_Direction'].isnull().sum().astype(str))\n",
    "    \n",
    "    df['Wind_Direction'] = df.groupby(['Airport_Code', 'Start_Time_Year', 'Start_Time_Month'])['Wind_Direction'].apply(\n",
    "        lambda x: x.fillna(Counter(x).most_common()[0][0]) if all(x.isnull()) == False else x)\n",
    "    print('Wind_Direction' + \" fill type 2 for Nan : \" + df['Wind_Direction'].isnull().sum().astype(str))\n",
    "    \n",
    "    df['Wind_Direction'] = df.groupby(['Airport_Code', 'Start_Time_Month'])['Wind_Direction'].apply(\n",
    "        lambda x: x.fillna(Counter(x).most_common()[0][0]) if all(x.isnull()) == False else x)\n",
    "    print('Wind_Direction' + \" fill type 3 for Nan : \" + df['Wind_Direction'].isnull().sum().astype(str))\n",
    "\n",
    "\n",
    "fill_mode_wind_direction(train)\n",
    "fill_mode_wind_direction(test)\n",
    "fill_mode_wind_direction(validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e7675b-55ce-4a27-9c0b-0a7a1037f431",
   "metadata": {
    "id": "r0QWSev3WMsG"
   },
   "source": [
    "### -------------> OBSERVATION\n",
    "<hr>\n",
    "\n",
    "> There still are some missing values in `Wind_Direction` but much less. Impute median by these features for the sake of simplicity.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16427eda-6502-478b-aed6-84da3e7c10f4",
   "metadata": {},
   "source": [
    "<a id=\"2.3.6\"></a>\n",
    "### 2.3.6 Impute Median and Mode for the rest- assume that there is random order of missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97e54d6-f225-4b8b-af07-3250ba6610b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select numeric columns\n",
    "numeric = train.select_dtypes(include=[np.number])\n",
    "train_numeric = numeric.columns.tolist()\n",
    "\n",
    "numeric = validation.select_dtypes(include=[np.number])\n",
    "validation_numeric = numeric.columns.tolist()\n",
    "\n",
    "numeric = test.select_dtypes(include=[np.number])\n",
    "test_numeric = numeric.columns.tolist()\n",
    "\n",
    "def impute_median_num_col(df, numeric_col):\n",
    "    # Imputes mode to NAN to the rest of categorical columns \n",
    "    for column in numeric_col:\n",
    "        df[column].fillna(df[column].median(), inplace=True)\n",
    "\n",
    "impute_median_num_col(train, train_numeric)\n",
    "impute_median_num_col(test, test_numeric)\n",
    "impute_median_num_col(validation, validation_numeric)\n",
    "\n",
    "# select non-numeric columns\n",
    "train_string = train.select_dtypes(include='string')\n",
    "test_string = test.select_dtypes(include='string')\n",
    "validation_string = validation.select_dtypes(include='string')\n",
    "\n",
    "def impute_mode_num_col(df, string_col):\n",
    "    # Imputes mode to NAN to the rest of categorical columns \n",
    "    for column in string_col:\n",
    "        df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "\n",
    "impute_mode_num_col(train, train_string)\n",
    "impute_mode_num_col(test, test_string)\n",
    "impute_mode_num_col(validation, validation_string)\n",
    "\n",
    "# display missing values in descending\n",
    "missing_percentage(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478954b7-7be6-41b0-aff3-df4a0e8b272b",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<a id=\"2.4\"></a>\n",
    "# 2.4 Shorten and Simplify categories \n",
    "\n",
    "<a id=\"2.4.1\"></a>\n",
    "### 2.4.1 Time-series columns - break them down into hour, minute, and weekday "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73b1013-2fb1-4ce2-858e-1e191b312025",
   "metadata": {},
   "source": [
    "### Number of accidents for hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0f137e-2687-469c-9e34-f906c3457cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the accident count for each hour\n",
    "df_hour = train['Start_Time_Hour'].value_counts().to_frame().reset_index().sort_values('Start_Time_Hour')\n",
    "df_hour.columns = ['Hour', 'Counts']\n",
    "\n",
    "# set fig size\n",
    "plt.figure(figsize=(20, 5))\n",
    "#set grid style\n",
    "sns.set_style(\"darkgrid\")\n",
    "# crete a line plot for accident count for each hours as a time series\n",
    "sns.lineplot(x='Hour', y='Counts', data=df_hour, color='pink')\n",
    "# set label, ticks and title\n",
    "plt.xticks(df_hour['Hour'])\n",
    "plt.ylabel('Accident Count', size=15)\n",
    "plt.xlabel('Hour', size=15)\n",
    "plt.title('Number of Accidents by Hour', size=18, y=1.05)\n",
    "# show graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e0876-e689-437e-87cc-550d4dd10c8a",
   "metadata": {},
   "source": [
    "### Number of accidents for Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940b0bbc-5a06-4a68-a86c-d1c9e2557908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import calendar for getting the month and week names\n",
    "import calendar\n",
    "\n",
    "# define the plot size\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "# create count plot for severity for each month\n",
    "sns.countplot(x='Start_Time_Month', hue='Severity', data=train)\n",
    "\n",
    "# set itle, labels and ticks\n",
    "plt.title('Accident Severity Count by Month', size=15, y=1.05)\n",
    "plt.ylabel(\"Number of Accidents\")\n",
    "plt.xticks(np.arange(0, 12, 1), calendar.month_name[1:13])\n",
    "# plt.yticks(np.linspace(25000,250000,6))\n",
    "\n",
    "#show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6eb90e-5eb4-4220-90b8-d8b0739a0fe1",
   "metadata": {},
   "source": [
    "### Number of accidents for Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2be671b-5c3e-4457-b877-951ccc3a78ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the figure size\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# create count plot for severity for each year\n",
    "sns.countplot(x='Start_Time_Year', hue='Severity', data=train)\n",
    "\n",
    "# set the ticks, labels and title\n",
    "plt.title('Accident Severity Count by Year', size=15, y=1.05)\n",
    "plt.ylabel(\"Number of Accidents\")\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7038684-f0d9-446c-aa01-1e3999a72cde",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"2.4.2\"></a>\n",
    "### 2.4.2 Shorten & Simplify the Wind Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e866a757-5bc2-4e3f-a1f3-b4015dba47d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Wind_Direction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa5cc14-a399-4afa-bc5d-4d1f37cdf0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_wind_direction(df):\n",
    "    df.loc[df['Wind_Direction'] == 'Calm', 'Wind_Direction'] = 'CALM'\n",
    "    df.loc[(df['Wind_Direction'] == 'West') | (df['Wind_Direction'] == 'WSW') | (\n",
    "            df['Wind_Direction'] == 'WNW'), 'Wind_Direction'] = 'W'\n",
    "    df.loc[(df['Wind_Direction'] == 'South') | (df['Wind_Direction'] == 'SSW') | (\n",
    "            df['Wind_Direction'] == 'SSE'), 'Wind_Direction'] = 'S'\n",
    "    df.loc[(df['Wind_Direction'] == 'North') | (df['Wind_Direction'] == 'NNW') | (\n",
    "            df['Wind_Direction'] == 'NNE'), 'Wind_Direction'] = 'N'\n",
    "    df.loc[(df['Wind_Direction'] == 'East') | (df['Wind_Direction'] == 'ESE') | (\n",
    "            df['Wind_Direction'] == 'ENE'), 'Wind_Direction'] = 'E'\n",
    "    df.loc[df['Wind_Direction'] == 'Variable', 'Wind_Direction'] = 'VAR'\n",
    "    print(\"Wind Direction after simplification: \", df['Wind_Direction'].unique())\n",
    "\n",
    "\n",
    "simplify_wind_direction(train)\n",
    "simplify_wind_direction(test)\n",
    "simplify_wind_direction(validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cbdf7b-2028-4f7d-831d-45611b7e64f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"2.4.3\"></a>\n",
    "### 2.4.3 Shorten ad Simplify the Weather Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd19f0-e8ff-413c-b4ce-1a7f74b8cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = train[\"Weather_Condition\"].value_counts()[:15]\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.title(\"Histogram distribution of the top 15 weather conditions in the dataset\")\n",
    "sns.barplot(counts.index, counts.values)\n",
    "plt.xlabel(\"Weather Condition\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81461fc6-0827-44de-b39a-50e7d68ebb6d",
   "metadata": {},
   "source": [
    "### -----------> OBSERVATION\n",
    "<hr>\n",
    "\n",
    "> According to Road Weather Management Program, most weather-related crashes happen on wet-pavement and during rainfall. Winter-condition and fog are another two main reasons for weather-related accidents. \n",
    "\n",
    "> To extract these three weather conditions, we first look at what we have in 'Weather_Condition' Feature.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaca8da-fee6-4b6a-98e1-943b122eb230",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Weather_Condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee199ba5-c237-4037-bcc4-ee131d020f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shorten weather conditions categories\n",
    "def simplify_weather_condition(df):\n",
    "    df.loc[df[\"Weather_Condition\"].str.contains(\"Thunder|T-Storm\", na=False), \"Weather_Condition\"] = \"Thunderstorm\"\n",
    "    df.loc[df[\"Weather_Condition\"].str.contains(\"Snow|Sleet|Wintry\", na=False), \"Weather_Condition\"] = \"Snow\"\n",
    "    df.loc[df[\"Weather_Condition\"].str.contains(\"Rain|Drizzle|Shower\", na=False), \"Weather_Condition\"] = \"Rain\"\n",
    "    df.loc[df[\"Weather_Condition\"].str.contains(\"Wind|Squalls\", na=False), \"Weather_Condition\"] = \"Windy\"\n",
    "    df.loc[df[\"Weather_Condition\"].str.contains(\"Hail|Pellets\", na=False), \"Weather_Condition\"] = \"Hail\"\n",
    "    df.loc[df[\"Weather_Condition\"].str.contains(\"Fair\", na=False), \"Weather_Condition\"] = \"Clear\"\n",
    "    df.loc[df[\"Weather_Condition\"].str.contains(\"Cloud|Overcast\", na=False), \"Weather_Condition\"] = \"Cloudy\"\n",
    "    df.loc[df[\"Weather_Condition\"].str.contains(\"Mist|Haze|Fog\", na=False), \"Weather_Condition\"] = \"Fog\"\n",
    "    df.loc[df[\"Weather_Condition\"].str.contains(\"Sand|Dust\", na=False), \"Weather_Condition\"] = \"Sand\"\n",
    "    df.loc[df[\"Weather_Condition\"].str.contains(\"Smoke|Volcanic Ash\", na=False), \"Weather_Condition\"] = \"Smoke\"\n",
    "    df.loc[df[\"Weather_Condition\"].str.contains(\"N/A Precipitation\", na=False), \"Weather_Condition\"] = \"Unknown\"\n",
    "\n",
    "    print(df[\"Weather_Condition\"].unique())\n",
    "\n",
    "simplify_weather_condition(train)\n",
    "simplify_weather_condition(test)\n",
    "simplify_weather_condition(validation)\n",
    "\n",
    "# print out the unique values in weather condition column for each dataset\n",
    "train_unique_weather = train[\"Weather_Condition\"].unique()\n",
    "test_unique_weather = test[\"Weather_Condition\"].unique()\n",
    "validation_unique_weather = validation[\"Weather_Condition\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd38399-e544-466a-819f-fe888c877f58",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br><br>\n",
    "<a id=\"2.5\"></a>\n",
    "# 2.5 Typos\n",
    "<a id=\"2.5.1\"></a>\n",
    "### 2.5.1 Check general spelling errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baccff8-4e5e-4f31-b83b-fc21b974ec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_string = train.select_dtypes(include='string')\n",
    "\n",
    "# Check if spelling errors, shoul clean further if the number of before checking and after checking are different\n",
    "for col in train_string:\n",
    "    print(f'Before: {col}: {len(set(train[col]))}; After: {col}: {len(set(train[col].str.title().str.strip()))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2823f1-1215-40ba-8849-8af86263b20a",
   "metadata": {},
   "source": [
    "### ----------> OBSERVATION\n",
    "<hr>\n",
    "\n",
    "> Indeed, there are typos in the `Street`, `City`, `County`, `Wind_Direction`. Let's fix it.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ea2886-7d4d-4a35-8037-8b3c3cd43fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the errors\n",
    "# train.Street = train.Street.str.title().str.strip()\n",
    "train.City = train.City.str.title().str.strip()\n",
    "train.County = train.County.str.title().str.strip()\n",
    "train.Wind_Direction = train.Wind_Direction.str.title().str.strip()\n",
    "\n",
    "# Correct the errors\n",
    "# test.Street = test.Street.str.title().str.strip()\n",
    "test.City = test.City.str.title().str.strip()\n",
    "test.County = test.County.str.title().str.strip()\n",
    "test.Wind_Direction = test.Wind_Direction.str.title().str.strip()\n",
    "\n",
    "# validation.Street = validation.Street.str.title().str.strip()\n",
    "validation.City = validation.City.str.title().str.strip()\n",
    "validation.County = validation.County.str.title().str.strip()\n",
    "validation.Wind_Direction = validation.Wind_Direction.str.title().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910649e9-dcf1-412c-9951-168d1d7e2f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if spelling errors already fixed\n",
    "for col in train_string:\n",
    "    print(f'Before: {col}: {len(set(train[col]))}; After: {col}: {len(set(train[col].str.title().str.strip()))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208995f1-14b4-45cb-882f-b29ae5bbc7e8",
   "metadata": {},
   "source": [
    "<a id=\"2.5.2\"></a>\n",
    "### 2.5.2 Extra-whitespaces\n",
    "Check whether there are instances of extra whitespaces and trim them in all dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e8cc67-bba2-4f16-a9f7-a8c1b30ddd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from function import whitespace_remover\n",
    "\n",
    "\"\"\"\n",
    "        Remove extra leading and tailing whitespace from the data.\n",
    "         pass dataframe as a parameter and apply whitespace_remover function on dataframe\n",
    "\"\"\"\n",
    "\n",
    "whitespace_remover(train)\n",
    "whitespace_remover(test)\n",
    "whitespace_remover(validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828b4912-f7f8-46b8-8ffe-ec741098644a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"2.5.3\"></a>\n",
    "### 2.5.3 Lower-case all values in each column\n",
    "\n",
    "+ Categorical data should have all the uniform formatting - lower case. \n",
    "+ I will cast all categorical data to lower case except the test set since I dont want my ID columns to be in lower case to match the ID in Kaggle competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2593c8eb-fb9a-47f0-99cb-1fc7f29f3cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast all values inside the dataframe (except the columns' name) into lowercase\n",
    "train = train.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "# test = test.applymap(lambda s: s.lower() if type(s) == str else s) // I dont want my ID to be lower case to match the ID in Kaggle competition\n",
    "validation = validation.applymap(lambda s: s.lower() if type(s) == str else s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ab30f3-1907-47d4-8d84-5462c0cf1e9e",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<a id=\"2.6\"></a>\n",
    "# 2.6 Sanity checks\n",
    "Design and run a small test-suite, consisting of a series of sanity checks to test for the presence of **impossible values** and **outliers** for each attribute.\n",
    "<a id=\"2.6.1\"></a>\n",
    "### 2.6.1 Check duplication\n",
    "+ Use the pandas function `.drop_duplicates()` to remove copied rows from a DataFrame\n",
    "\n",
    "+ Could not drop duplicated in TEST since I'll use it to compete in Kaggle learboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04378976-b4c6-4773-835c-692702f70542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "print(\"Number of rows before drop of duplicates  in TRAIN:\", len(train.index))\n",
    "print(\"Number of duplicated records in TRAIN: \", train.duplicated().sum())\n",
    "train.drop_duplicates(inplace=True)\n",
    "print(\"Number of rows after drop of duplicates in TRAIN:\", len(train.index), \"\\n\\n\")\n",
    "\n",
    "\n",
    "# VALIDATION\n",
    "print(\"Number of rows before drop of duplicates in VALIDATION:\", len(validation.index))\n",
    "print(\"Number of duplicated records in VALIDATION: \", validation.duplicated().sum())\n",
    "validation.drop_duplicates(inplace=True)\n",
    "print(\"Number of rows after drop of duplicates in VALIDATION:\", len(validation.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93397acb-c61c-404d-abd0-9392920bb778",
   "metadata": {},
   "source": [
    "<a id=\"2.6.2\"></a>\n",
    "### 2.6.2 Impossible values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b1f14-26fe-45e3-98a5-3a14de23a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9328047-ec68-46b5-ae62-21f744682f7b",
   "metadata": {},
   "source": [
    "### -----> OSERVATION\n",
    "\n",
    "<hr>\n",
    "\n",
    "> The **minimum value for `Pressure(in)`, `Visibility(mi)` is 0**, meaning that some records are missing them and replaced them by putting zeros. For this reason, I'm going to drop the records for these two columns for TRAIN and VALIDATION datasets\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed13d52-4124-474f-831f-1ca607738c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows that have Pressure and Visibility equal and below 0\n",
    "\n",
    "train = train[train[\"Pressure(in)\"] != 0]\n",
    "train = train[train[\"Visibility(mi)\"] != 0]\n",
    "\n",
    "validation = validation[validation[\"Pressure(in)\"] != 0]\n",
    "validation = validation[validation[\"Visibility(mi)\"] != 0]\n",
    "\n",
    "\n",
    "print(\"TRAIN DATASET: \")\n",
    "print(train[[\"Pressure(in)\", \"Visibility(mi)\"]].describe().round(2))\n",
    "\n",
    "print(\"VALIDATION DATASET: \")\n",
    "print(validation[[\"Pressure(in)\", \"Visibility(mi)\"]].describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1c0e43-8017-4dae-b75c-2970f9bda838",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<a id=\"2.7\"></a>\n",
    "# 2.7 Extra exploration and visualization\n",
    "<a id=\"2.7.1\"></a>\n",
    "### 2.7.1 Medium distance by severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ed416a-7a59-4a83-8644-8dd6b92eabb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar charts for Medium distance by severity\n",
    "severity_distance = train.groupby(\"Severity\").mean()[\"Distance(mi)\"].sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.title(\"Medium distance by severity\")\n",
    "sns.barplot(severity_distance.values, severity_distance.index, orient=\"h\", order=severity_distance.index, color='pink')\n",
    "plt.xlabel(\"Distance (mi)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e194136b-cb10-41df-be25-9b0e1854c323",
   "metadata": {},
   "source": [
    "### ------------> OBSERVATION\n",
    "\n",
    "<hr>\n",
    "\n",
    "> The graph shows the accident is more or less proportional to the severity\n",
    "\n",
    "> The accidents with severity level of 4 have the longest distance. \n",
    "\n",
    "> The longer the distance, the more severe the accidents\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95325f18-c4d6-4d86-8198-bf116900d50e",
   "metadata": {},
   "source": [
    "<a id=\"2.7.3\"></a>\n",
    "### 2.7.2 Top 10 states having the most accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a58d5f-a36f-4975-beaf-19d99cfba6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# visualize top 10 states having the most accidents\n",
    "state_percentage = train['State'].value_counts() * 100 / len(train)\n",
    "\n",
    "# state_count\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(state_percentage.values[:10], state_percentage.index[:10], color='pink')\n",
    "plt.title('Frequency Distribution of Top 10 States')\n",
    "\n",
    "plt.ylabel('States', fontsize=12)\n",
    "plt.xlabel('Percentage of Accident', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677070bf-6dd5-4003-af17-298d2a448d5b",
   "metadata": {},
   "source": [
    "### ----------> OBSERVATION\n",
    "<hr>\n",
    "\n",
    "> The state having the most number of accidents is California (28%) followed by Florida(10%).\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b2f00f-cccb-4cd9-8293-6178e1f04b28",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"2.7.3\"></a>\n",
    "### 2.7.3 Longtitude and Latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a4c858-9e4e-4067-b635-ce9ac80b735f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Make scatter for Latitude and Longitude\n",
    "plt.figure(figsize=(15, 12))\n",
    "plt.scatter(x=train.Start_Lng, y=train.Start_Lat, s=15, color='pink')\n",
    "plt.title(\"Start Latitude and Longitude from February 2016 to Dec 2020 for the Contiguous United States\", fontsize=25)\n",
    "plt.xlabel(\"Start Longitude\", fontsize=18)\n",
    "plt.ylabel(\"Start Latitude\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cfa5a7-be47-4d46-a0b4-07c2d9981807",
   "metadata": {},
   "source": [
    "### ----------> OBSERVATION\n",
    "<hr>\n",
    "\n",
    "> The density of points is more at the eastern and western coasts as compared to the middle of the country indicates that more accidents recorded at the 2 sides from February 2016 to Dec 2020 in the Contiguous United States rather than its middle part. \n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f57791c-5372-4e69-87a1-d27bc0dfb988",
   "metadata": {},
   "source": [
    "<a id=\"2.7.3\"></a>\n",
    "### 2.7.3 Most frequent POI Attributes of an accident with severity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26011c04-3d0d-41ee-bf16-8736693b7507",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_features = [\"Amenity\", \"Bump\", \"Crossing\", \"Give_Way\", \"Junction\", \"No_Exit\", \"Railway\", \"Roundabout\", \"Station\",\n",
    "                 \"Stop\", \"Traffic_Calming\", \"Traffic_Signal\"]\n",
    "data = train[road_features].sum().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.title(\"Most frequent road features\")\n",
    "sns.barplot(data.values, data.index, orient=\"h\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Road feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ac9953-66e3-4eda-b59e-39d15599ab34",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "\n",
    "<hr>\n",
    "\n",
    "> The most fatal accidents occurred near a traffic signal, junction and crossing was present. The driver might fail to pay attention before pulling out due to impatience, impairment of one form or another, or a simple failure to judge the distance and speed of an oncoming vehicle.\n",
    "\n",
    "> The fourth most common road feature, instead, was the presence of a nearby station, probably because of the high presence of vehicles.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c59300-2b60-4d0d-8ff5-1cece244c9f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### WRITING CLEANED DATA BACK TO FILES\n",
    "After completing your analysis and adding new columns, I write the results back to cosc2789-2021 folder. Otherwise, the data will be lost when the Jupyter Lab shuts down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdde0b2a-236f-4c77-9a67-c5b48787f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To write the data from the data frame into a file, use the to_csv function.\n",
    "# train.to_csv('cosc2789-2021/cleaned_train.csv', index=False)\n",
    "# test.to_csv('cosc2789-2021/cleaned_test.csv', index=False)\n",
    "# validation.to_csv('cosc2789-2021/cleaned_validation.csv', index=False)\n",
    "# print(\"Cleaned data was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0695dc-5d1e-45c1-81c3-dfeaf545915f",
   "metadata": {
    "papermill": {
     "duration": 0.030733,
     "end_time": "2020-11-05T19:50:02.163472",
     "exception": false,
     "start_time": "2020-11-05T19:50:02.132739",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1 style=\"color:#ffc0cb;font-size:40px;font-family:Georgia;text-align:center;\"><strong>3. Feature Engineering</strong></h1>\n",
    "\n",
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bd5a2e-3569-4fcf-89a3-a750208bd94c",
   "metadata": {
    "papermill": {
     "duration": 0.790393,
     "end_time": "2020-11-05T19:50:06.516740",
     "exception": false,
     "start_time": "2020-11-05T19:50:05.726347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Total missing values in TRAIN:\", train.isna().sum().sum())\n",
    "print(\"Total missing values in TEST:\", test.isna().sum().sum())\n",
    "print(\"Total missing values in VALIDATION:\", validation.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ce6ee1-5ca7-4fb2-8c4a-218e6c047b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab7efb7-79a6-49ab-b387-351579ec3fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8299a-252c-4dbf-82de-eb53e6949b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentage(validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f22a497-f7e5-4479-8643-11794c0a8315",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"3.1\"></a>\n",
    "### 3.1 Data Correlation - Quantify the association of features and accidents\n",
    "\n",
    "To quantify the pairwise relationships, I compute the Pearson correlation coefficient matrix. \n",
    "\n",
    "0.2 = weak;\n",
    "0.5 = medium;\n",
    "0.8 = strong;\n",
    "0.9 = very strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ad7550-62a5-4345-ba84-c49a79e1e2bd",
   "metadata": {
    "_cell_guid": "6b9a990b-648b-4e81-a312-cc29ae7ff11a",
    "_kg_hide-input": true,
    "_uuid": "9df6eafa-024c-4b9b-b065-4cea0185017a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (f\"Train has {train.shape[0]} rows and {train.shape[1]} columns\")\n",
    "print (f\"Test has {test.shape[0]} rows and {test.shape[1]} columns\")\n",
    "print (f\"Validation has {validation.shape[0]} rows and {validation.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff0fd9d-8f45-4b75-bf03-bf73ee35300a",
   "metadata": {
    "_cell_guid": "cbc23ba7-29e1-4f93-bb70-7a0eeb051f3b",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "9214537f-91da-4c0a-9f47-dd53650587de"
   },
   "outputs": [],
   "source": [
    "# gives us statistical info about the numerical variables. \n",
    "train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ad662-2876-42ed-ab9c-ab0509cbecec",
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def plotting_3_chart(df, feature):\n",
    "    ## Importing seaborn, matplotlab and scipy modules. \n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.gridspec as gridspec\n",
    "    from scipy import stats\n",
    "    import matplotlib.style as style\n",
    "    style.use('fivethirtyeight')\n",
    "\n",
    "    ## Creating a customized chart. and giving in figsize and everything. \n",
    "    fig = plt.figure(constrained_layout=True, figsize=(12,8))\n",
    "    ## creating a grid of 3 cols and 3 rows. \n",
    "    grid = gridspec.GridSpec(ncols=3, nrows=3, figure=fig)\n",
    "    #gs = fig3.add_gridspec(3, 3)\n",
    "\n",
    "    ## Customizing the histogram grid. \n",
    "    ax1 = fig.add_subplot(grid[0, :2])\n",
    "    ## Set the title. \n",
    "    ax1.set_title('Histogram')\n",
    "    ## plot the histogram. \n",
    "    sns.distplot(df.loc[:,feature], norm_hist=True, ax = ax1)\n",
    "\n",
    "    # customizing the QQ_plot. \n",
    "    ax2 = fig.add_subplot(grid[1, :2])\n",
    "    ## Set the title. \n",
    "    ax2.set_title('QQ_plot')\n",
    "    ## Plotting the QQ_Plot. \n",
    "    stats.probplot(df.loc[:,feature], plot = ax2)\n",
    "\n",
    "    ## Customizing the Box Plot. \n",
    "    ax3 = fig.add_subplot(grid[:, 2])\n",
    "    ## Set title. \n",
    "    ax3.set_title('Box Plot')\n",
    "    ## Plotting the box plot. \n",
    "    sns.boxplot(df.loc[:,feature], orient='v', ax = ax3 );\n",
    "    \n",
    "plotting_3_chart(train, 'Severity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc5c7ff-b13b-4a7a-9e21-a3690bf8ce04",
   "metadata": {
    "_cell_guid": "67c66715-2ba3-4245-9759-1047606e4f12",
    "_uuid": "f1be8cbe-c8cc-4096-a38b-a81c939653f4"
   },
   "source": [
    "These **three** charts above can tell us a lot about our target variable.\n",
    "\n",
    "> Our target variable, **Severity** is not normally distributed.\n",
    "\n",
    "> Our target variable is right-skewed. \n",
    "\n",
    "> There are multiple outliers in the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf8d683-a786-42c7-889f-4f4e41787e67",
   "metadata": {
    "_cell_guid": "dbf1c7a3-c1cf-4a59-b7be-08c65fa50fad",
    "_kg_hide-input": true,
    "_uuid": "6198f8cd-82de-49c5-a7c8-35b0bf5df409"
   },
   "outputs": [],
   "source": [
    "#skewness and kurtosis\n",
    "print(\"Skewness: \" + str(train['Severity'].skew()))\n",
    "print(\"Kurtosis: \" + str(train['Severity'].kurt()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3079a307-ec5a-496d-b1eb-228b10be28ac",
   "metadata": {
    "_cell_guid": "71602011-62bf-436f-b4a5-fe1ef34e2d97",
    "_uuid": "2f508e99-97b3-4522-9569-ab32b8d6c810"
   },
   "source": [
    "### --------> OBSERVATION\n",
    "\n",
    "<hr>\n",
    "\n",
    "<b>Positive Skewness</b>\n",
    "\n",
    "These **three** charts above can tell us a lot about our target variable. There are quite a bit Skewness and Kurtosis in the target variable. \n",
    "\n",
    "> Our target variable, **Severity** is not normally distributed and it is right-skewed. \n",
    "\n",
    "> There are multiple outliers in the variable.\n",
    "\n",
    "> Similar to our target variable distribution means the mean and median will be greater than the mode similar to this dataset. Which means more more sever case by car accident than the average case.\n",
    "\n",
    "\n",
    "<b>Kurtosis</b> \n",
    "> My target variable shows an unequal level of variance across most independent variables. This **Heteroscedasticity** is a red flag for the multiple linear regression model.\n",
    "\n",
    "*In probability theory and statistics, **Kurtosis** is the measure of the outliers present in my distribution.*\n",
    "\n",
    "> There are many outliers in the scatter plots above that took my attention. \n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723858be",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "numeric_feats = train.dtypes[train.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5789e098",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"3.2\"></a>\n",
    "### 3.2 [Box Cox Transformation of (highly) skewed features](https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.special.boxcox1p.html)\n",
    "+ We use the scipy function boxcox1p which computes the Box-Cox transformation of  1+x .\n",
    "\n",
    "+ Note that setting  λ=0  is equivalent to log1p used above for the target variable.\n",
    "\n",
    "+ See this page for more details on Box Cox Transformation as well as the scipy function's page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe380620",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from scipy.special import boxcox1p\n",
    "\n",
    "# # find skewness function\n",
    "# def find_skewness(df):\n",
    "#     numeric_feats = df.dtypes[df.dtypes != \"object\"].index\n",
    "#     # Check the skew of all numerical features\n",
    "#     skewed_feats = df[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "#     print(\"\\nSkew in numerical features: \\n\")\n",
    "#     skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "#     return skewness\n",
    "\n",
    "# def log_transform(df):\n",
    "#     numeric_feats = df.dtypes[df.dtypes != \"object\"].index\n",
    "#     # Check the skew of all numerical features\n",
    "#     skewed_feats = df[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "#     print(\"\\nSkew in numerical features: \\n\")\n",
    "#     skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "#     skewed_features = skewness[abs(skewness) > 0.75].index\n",
    "#     for feat in skewed_features:\n",
    "#         print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "#         df[feat] = np.log1p(df[feat])\n",
    "\n",
    "\n",
    "# def boxcox_transform(df):\n",
    "#     numeric_feats = df.dtypes[df.dtypes != \"object\"].index\n",
    "#     # Check the skew of all numerical features\n",
    "#     skewed_feats = df[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "#     print(\"\\nSkew in numerical features: \\n\")\n",
    "#     skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "#     skewed_features = skewness[abs(skewness) > 0.75].index\n",
    "#     for feat in skewed_features:\n",
    "#         print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "#         df[feat] = boxcox1p(df[feat], 0.15)\n",
    "\n",
    "# boxcox_transform(train)\n",
    "# boxcox_transform(test)\n",
    "# boxcox_transform(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ede66-99fe-4342-be56-ceda59e74754",
   "metadata": {
    "_cell_guid": "b1aeb267-3868-470d-87bc-1d3d02832dd9",
    "_kg_hide-input": true,
    "_uuid": "02155550-8856-4aad-9f40-a757774a7ab2"
   },
   "outputs": [],
   "source": [
    "## Getting the correlation of all the features with target variable. \n",
    "(train.corr()**2)[\"Severity\"].sort_values(ascending = False)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc30bb9-be84-406b-b7f0-11b0249f5564",
   "metadata": {
    "_cell_guid": "b06bd2d5-6523-42b4-8db6-cac4df7e8ef2",
    "_uuid": "a5ead127-432f-4c17-8d90-8e1bad62f249"
   },
   "source": [
    "### ---> OBSERVATION\n",
    "\n",
    "> These are the predictor variables sorted in a descending order starting with the most correlated one **Start_Lng**. \n",
    "\n",
    "> The results showed that the parameters such as Start_Lng', 'Distance(mi)', 'Humidity(%)', 'Pressure(in)', 'Wind_Speed(mph)' were the most prominent factors which increase the severity of crashes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8342d9-1dfb-49c7-af2f-06ba798647e0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"3.3\"></a>\n",
    "### 3.3 Assumptions of Regression\n",
    "\n",
    "* **Linearity ( Correct functional form )** \n",
    "* **Homoscedasticity ( Constant Error Variance )( vs Heteroscedasticity )**\n",
    "* **Independence of Errors ( vs Autocorrelation )**\n",
    "* **Multivariate Normality ( Normality of Errors )**\n",
    "* **No or little Multicollinearity** \n",
    "\n",
    "> So, **How do I check regression assumptions? We fit a regression line and look for the variability of the response data along the regression line.** Let's apply this to each one of them.\n",
    "\n",
    "> **Linearity(Correct functional form):** \n",
    "Linear regression needs the relationship between each independent variable and the dependent variable to be linear. The linearity assumption can be tested with scatter plots. The following two examples depict two cases, where no or little linearity is present. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8263bf-9e6b-4b07-87d2-ec2e79c9e3a3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Removing multicollinary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d5160-2075-4bd8-a4ae-f777b30e9fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot sizing. \n",
    "fig, (ax1, ax2) = plt.subplots(figsize = (12,8), ncols=2,sharey=False)\n",
    "## Scatter plotting for Severity and Distance(mi).\n",
    "sns.scatterplot( x = train['Distance(mi)'], y = train.Severity,  ax=ax1)\n",
    "## Putting a regression line. \n",
    "sns.regplot(x=train['Distance(mi)'], y=train.Severity, ax=ax1)\n",
    "\n",
    "## Scatter plotting for Severity and ['Wind_Speed(mph)'].\n",
    "sns.scatterplot(x = train['Wind_Speed(mph)'],y = train.Severity, ax=ax2, color='pink')\n",
    "## regression line for MasVnrArea and Severity.\n",
    "sns.regplot(x=train['Wind_Speed(mph)'], y=train.Severity, ax=ax2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415a4b25-9245-4748-90b3-072b9384998b",
   "metadata": {
    "_cell_guid": "b8506cb7-41ec-494e-8af5-87ce9b55745c",
    "_uuid": "9fac9095-b1a8-4ce1-951e-ef2201ca0f68"
   },
   "source": [
    "Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0440e9c6-c0bf-4222-8c52-29c93e29be7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (12,8))\n",
    "sns.residplot(train['Distance(mi)'], train.Severity, color='pink');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee64009-c118-444e-a797-1b64026ce007",
   "metadata": {},
   "source": [
    "Distance(mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85bc83a-0d35-4511-9a29-2ac2563cbdbc",
   "metadata": {
    "_cell_guid": "b8713a9b-157c-4baf-9562-b3be0d387dbf",
    "_kg_hide-input": true,
    "_uuid": "6389a025-86ea-4162-b72b-d2da796e3f51"
   },
   "outputs": [],
   "source": [
    "plotting_3_chart(train, 'Severity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd344a58-34e2-4d88-a04c-d4dc96e7cb94",
   "metadata": {
    "_cell_guid": "70910039-1350-4a89-b3d1-600afa19b421",
    "_uuid": "8abe5e4b-4b35-4fdf-9cac-67c8a1de9a38"
   },
   "source": [
    "Now, let's make sure that the target variable follows a normal distribution. If you want to learn more about the probability plot(Q-Q plot), try [this](https://www.youtube.com/watch?v=smJBsZ4YQZw) video. You can also check out [this](https://www.youtube.com/watch?v=9IcaQwQkE9I) one if you have some extra time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d3897b-6cff-46f1-a3b9-272ca97e0db2",
   "metadata": {
    "_cell_guid": "8af2e89b-d316-45ae-8053-68bf53b15f87",
    "_kg_hide-input": true,
    "_uuid": "ef5a8648-6d0e-40de-9bd3-d71d9d9cba4a"
   },
   "outputs": [],
   "source": [
    "# ## transforming target variable using numpy.log1p,\n",
    "# train[\"Severity\"] = np.log1p(train[\"Severity\"])\n",
    "#\n",
    "# ## Plotting the newly transformed response variable\n",
    "# plotting_3_chart(train, 'Severity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d73932-ac8b-41a4-879f-70bf617eafd3",
   "metadata": {
    "_cell_guid": "9eef0002-26bb-41f9-bc18-07832d848410",
    "_uuid": "e908bc68-dec3-46b8-a021-7c03d5a08a7b"
   },
   "source": [
    "### ---------> Observation\n",
    "\n",
    "<hr>\n",
    "\n",
    "* There are multiple types of features including int, object, and float\n",
    "* No feature have missing values. \n",
    "\n",
    "> I want to focus on the target variable which is **Severity.** Let's create a histogram to see **if the features are normally distributed**. This is one of the assumptions of multiple linear regression. \n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e8602c-3264-49dc-9abe-3d37b1f7cdee",
   "metadata": {
    "_cell_guid": "a17ad845-6fca-4d47-8e44-7c4c44f0427d",
    "_execution_state": "idle",
    "_uuid": "be3b0157031685ed3dbc31a657ba712312691830",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "\n",
    "sns.distplot(train['Severity'] , fit=norm);\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(train['Severity'])\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "\n",
    "#Now plot the distribution\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Severity distribution')\n",
    "\n",
    "#Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['Severity'], plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82a917e-1bad-4ab2-9ef4-ff473f875027",
   "metadata": {},
   "source": [
    "As you can see, the log transformation removes the normality of errors, which solves most of the other errors we talked about above. Let's make a comparison of the pre-transformed and post-transformed state of residual plots. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064f00f4-ba6d-4441-9349-528cfb5f1f3d",
   "metadata": {
    "_cell_guid": "7b8eb81b-7d4a-4461-84ba-a84dacbf060b",
    "_uuid": "0b5fc8ff-4aa3-44b3-95e2-b8b6f7ed3e47"
   },
   "source": [
    "### ------> OBSERVATION\n",
    "> Here, we see that the pre-transformed chart on the left has heteroscedasticity, and the post-transformed chart on the right has Homoscedasticity(almost an equal amount of variance across the zero lines). It looks like a blob of data points and doesn't seem to give away any relationships. That's the sort of relationship we would like to see to avoid some of these assumptions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92e0e6d-50f4-41e1-9340-0051208a79c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 16. Data Correlation\n",
    "\n",
    "###### 4. Quantify the association of features and accidents\n",
    "\n",
    "As we look through these scatter plots, I realized that it is time to explain the assumptions of Multiple Linear Regression. Before building a multiple linear regression model, we need to check that these assumptions below are valid.\n",
    "\n",
    "We can already see some potentially interesting relationships between the target variable (the number of fatal accidents) and the feature variables (the remaining three columns).\n",
    "\n",
    "To quantify the pairwise relationships that we observed in the scatter plots, we can compute the Pearson correlation coefficient matrix. The Pearson correlation coefficient is one of the most common methods to quantify correlation between variables, and by convention, the following thresholds are usually used:\n",
    "\n",
    "0.2 = weak\n",
    "0.5 = medium\n",
    "0.8 = strong\n",
    "0.9 = very strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cff2de-a452-4611-842f-74f92e8516b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8508500-e184-42cb-b379-9866f566ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare severity level rate across numerical columns\n",
    "pd.pivot_table(train, index = 'Severity', values = ['Start_Lat', 'Start_Lng', 'End_Lat', 'End_Lng', 'Distance(mi)', 'Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)', 'Precipitation(in)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2453cccd-5917-4669-9a8c-cc27605cde02",
   "metadata": {},
   "source": [
    "**-----------> OBSERVATION**\n",
    "> Diverse range of values for different features\n",
    "\n",
    "> I might need to use scaling to unify the range of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bccdc04-303a-4975-8ff0-da012bbaf884",
   "metadata": {},
   "source": [
    "## Multicollinearity of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a32e0e1-1917-436a-912f-859ed077789b",
   "metadata": {
    "_cell_guid": "17ca1469-643b-4ba0-a141-32025d393bf5",
    "_kg_hide-input": true,
    "_uuid": "d841864f-d559-40f6-9b85-ac3ae8402e80"
   },
   "outputs": [],
   "source": [
    "def customized_scatterplot(y, x):\n",
    "        ## Sizing the plot. \n",
    "    style.use('fivethirtyeight')\n",
    "    plt.subplots(figsize = (12,8))\n",
    "    ## Plotting target variable with predictor variable(OverallQual)\n",
    "    sns.scatterplot(y = y, x = x)\n",
    "\n",
    "## Plot fig sizing. \n",
    "plt.style.use('ggplot')\n",
    "sns.set_style('whitegrid')\n",
    "plt.subplots(figsize = (30,20))\n",
    "## Plotting heatmap. \n",
    "\n",
    "# Generate a mask for the upper triangle (taken from seaborn example gallery)\n",
    "mask = np.zeros_like(train.corr(), dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "sns.heatmap(train.corr(), \n",
    "            cmap=sns.diverging_palette(20, 220, n=200), \n",
    "            mask = mask, \n",
    "            annot=True,\n",
    "            fmt = \".2f\",\n",
    "            center = 0, \n",
    "           );\n",
    "\n",
    "## Give title. \n",
    "plt.title(\"Heatmap of all the Features\", fontsize = 30);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5449a7e4-ed7a-4011-8801-b572fad02dbb",
   "metadata": {},
   "source": [
    "### ---------> OBSERVATION\n",
    "<hr>\n",
    "\n",
    "+ From the matrix we can see that the start and end GPS coordinates of the accidents are highly correlated.\n",
    "\n",
    "+ In fact, from the medium distance shown before, the end of the accident is usually close to the start, so we can consider just one of them for the machine learning models.\n",
    "\n",
    "+ Moreover, the wind chill (temperature) is directly proportional to the temperature, so we can also drop one of them.\n",
    "\n",
    "+ We can also see that the presence of a traffic signal is slightly correlated to the severity of an accident meaning that maybe traffic lights can help the traffic flow when an accident occurs.\n",
    "\n",
    "+ From the matrix we can also note that we couldn't compute the covariance with Turning_Loop, and that's because it's always False.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33513b6d-cf27-4a60-9c4a-5e847a087c5d",
   "metadata": {
    "papermill": {
     "duration": 0.030733,
     "end_time": "2020-11-05T19:50:02.163472",
     "exception": false,
     "start_time": "2020-11-05T19:50:02.132739",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Drop Multicollinearity features and high p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a40c7-83e0-4bac-99f5-8d6e3394fb8d",
   "metadata": {
    "papermill": {
     "duration": 0.790393,
     "end_time": "2020-11-05T19:50:06.516740",
     "exception": false,
     "start_time": "2020-11-05T19:50:05.726347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Total missing values in TRAIN:\", train.isna().sum().sum())\n",
    "print(\"Total missing values in TEST:\", test.isna().sum().sum())\n",
    "print(\"Total missing values in VALIDATION:\", validation.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4b17ee-c499-493e-9fbd-d18519f893a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select non-numeric columns\n",
    "categorical = train.select_dtypes(exclude=[np.number])\n",
    "categorical = categorical.columns.tolist()\n",
    "print(f'List of non numeric in train dataset is {categorical}\\n\\n')\n",
    "\n",
    "\n",
    "# select numeric columns\n",
    "numeric = train.select_dtypes(include=[np.number])\n",
    "numeric = numeric.columns.tolist()\n",
    "print(f'List of numeric in test dataset is {numeric}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e0c19-c856-47f0-812b-3f6f93d1a027",
   "metadata": {
    "papermill": {
     "duration": 0.109472,
     "end_time": "2020-11-05T19:50:08.044695",
     "exception": false,
     "start_time": "2020-11-05T19:50:07.935223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unneeded_columns = ['State', 'Side', 'City', 'County', 'Zipcode', 'Airport_Code', 'Wind_Direction', 'Weather_Condition', 'Amenity', 'Bump',\n",
    "                    'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Sunrise_Sunset', \n",
    "                    'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight', \n",
    "                    'Start_Lat', 'End_Lat', 'End_Lng', 'Temperature(F)', 'Visibility(mi)', 'Precipitation(in)', \n",
    "                    'Start_Time_Month', 'Start_Time_Year', 'Start_Time_Hour', 'End_Time_Month', 'End_Time_Year', 'End_Time_Hour', 'Weather_Timestamp_Month', 'Weather_Time_Hour']\n",
    "\n",
    "data = train.drop(unneeded_columns, axis=1)\n",
    "test = test.drop(unneeded_columns, axis=1)\n",
    "validation = validation.drop(unneeded_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e9064-3123-4ff9-bffd-a5ed1d9a3f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select non-numeric columns\n",
    "categorical = data.select_dtypes(exclude=[np.number])\n",
    "categorical = categorical.columns.tolist()\n",
    "print(f'List of non numeric in train dataset is {categorical}\\n\\n')\n",
    "\n",
    "\n",
    "# select numeric columns\n",
    "numeric = data.select_dtypes(include=[np.number])\n",
    "numeric = numeric.columns.tolist()\n",
    "print(f'List of numeric in test dataset is {numeric}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c611daf-dd05-4f6d-a278-b41873b01af8",
   "metadata": {
    "papermill": {
     "duration": 0.040383,
     "end_time": "2020-11-05T19:50:10.287341",
     "exception": false,
     "start_time": "2020-11-05T19:50:10.246958",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57140fe-9a6f-4ed4-9b05-a42641b04baf",
   "metadata": {},
   "source": [
    "## c. Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a85a31-092c-4c4f-a435-391894ef2c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(30,8))\n",
    "\n",
    "for xcol, ax in zip(['Start_Lng', 'Distance(mi)', 'Humidity(%)', 'Pressure(in)', 'Wind_Speed(mph)'], axes):\n",
    "    data.plot(kind='scatter', x=xcol, y='Severity', ax=ax, alpha=0.4, color='pink')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb4dff1-0bf3-4503-b512-e641e12e1e2a",
   "metadata": {},
   "source": [
    "### -------> OBSERVATION:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde7dc24-32ae-4508-9d3d-8d558314c61d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Encoding binary columns\n",
    "data = data.replace([True, False], [1,0])\n",
    "test = test.replace([True, False], [1,0])\n",
    "validation = validation.replace([True, False], [1,0])\n",
    "\n",
    "\n",
    "# Encoding nominal columns\n",
    "def onehot_encode(df, columns, prefixes):\n",
    "    df = df.copy()\n",
    "    for column, prefix in zip(columns, prefixes):\n",
    "        dummies = pd.get_dummies(df[column], prefix=prefix)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        df = df.drop(column, axis=1)\n",
    "    return df\n",
    "\n",
    "data = onehot_encode(\n",
    "    data,\n",
    "    columns=['Timezone', 'Crossing', 'Traffic_Signal'],\n",
    "    prefixes=['Timezone', 'Crossing', 'Traffic_Signal']\n",
    ")\n",
    "\n",
    "test = onehot_encode(\n",
    "    test,\n",
    "    columns=['Timezone', 'Crossing', 'Traffic_Signal'],\n",
    "    prefixes=['Timezone', 'Crossing', 'Traffic_Signal']\n",
    ")\n",
    "\n",
    "validation = onehot_encode(\n",
    "    validation,\n",
    "    columns=['Timezone', 'Crossing', 'Traffic_Signal'],\n",
    "    prefixes=['Timezone', 'Crossing', 'Traffic_Signal']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0164dd5b-af71-4c26-8f47-d6e9965ebc82",
   "metadata": {
    "papermill": {
     "duration": 0.12063,
     "end_time": "2020-11-05T19:50:22.219598",
     "exception": false,
     "start_time": "2020-11-05T19:50:22.098968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606eddf8-482f-40a4-81df-aa24b9da4fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'Severity ~ '+ '+'.join(data.columns[1:])\n",
    "formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2967284f-5aff-4e11-ad3d-6bcf18fc254b",
   "metadata": {},
   "source": [
    "### Ols stats model - Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90566a1a-564b-4da2-b05e-17b17522803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Rename the copy DataFrame to fit into stats model\n",
    "data1 = data.rename(columns={'Distance(mi)': 'Distance_mi', 'Humidity(%)': 'Humidity_perc', 'Pressure(in)': 'Pressure_in', 'Wind_Speed(mph)': 'Wind_Speed_mph'})\n",
    "\n",
    "formula = 'Severity ~ '+ '+'.join(data1.columns[1:])\n",
    "\n",
    "model = ols(formula='Severity ~ Start_Lng+Distance_mi+Humidity_perc+Pressure_in+Wind_Speed_mph+Weather_Timestamp_Year+Crossing_0+Crossing_1+Traffic_Signal_0+Traffic_Signal_1', data=data1).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5847d3fc-1ca7-4c04-90dd-903626dae300",
   "metadata": {},
   "source": [
    "### -------------> OBSERVATION\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Interpretation of the Model Coefficient, the P-value, the R-squared\n",
    "> The output above shows that, when the other variables remain constant, if we compare two applicants whose 'Weather_Timestamp_Year[T.2017]' differ by one unit, the applicant with higher 'Weather_Timestamp_Year[T.2017]' will, on average, have 0.0156 units higher 'Income'.\n",
    "> Using the P>|t| result, I can infer that the variables all independent variables are the statistically significant variables, as their p-value is less than 0.05.\n",
    "> The Adj. R-squared 0.130 indicates the amount of variability not being explained by my model that much\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645abc39-395c-44f5-b629-4b98aa3f4eff",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<h1 style=\"color:#ffc0cb;font-size:40px;font-family:Georgia;text-align:center;\"><strong>3. Feature Engineering</strong></h1>\n",
    "Model evaluation and export\n",
    "\n",
    "## Train - Test -  Validation\n",
    "\n",
    "+ Train dataset for train set\n",
    "\n",
    "+ Validation for test set\n",
    "\n",
    "+ Test for prediction on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95db1f30-5526-4178-874e-7285998ad33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Severity'], axis = 1)\n",
    "y = data['Severity']\n",
    "\n",
    "X_train = X\n",
    "y_train = y\n",
    "\n",
    "accident_ID = test.ID.to_list()\n",
    "TEST = test.drop(['ID'], axis = 1)\n",
    "\n",
    "X_test = validation.drop(['Severity'], axis = 1)\n",
    "y_test = validation['Severity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c09852-5aaa-4bce-922d-c213d5c1d7b6",
   "metadata": {},
   "source": [
    "# 📦 Preparing Data For Multiple Linear Regression\n",
    "> Linear regression is been studied at great length, and there is a lot of literature on how your data must be structured to make best use of the model.\n",
    "\n",
    "> As such, there is a lot of sophistication when talking about these requirements and expectations which can be intimidating. In practice, you can uses these rules more as rules of thumb when using Ordinary Least Squares Regression, the most common implementation of linear regression.\n",
    "\n",
    "> Try different preparations of your data using these heuristics and see what works best for your problem.\n",
    "- **Linear Assumption.** Linear regression assumes that the relationship between your input and output is linear. It does not support anything else. This may be obvious, but it is good to remember when you have a lot of attributes. You may need to transform data to make the relationship linear (e.g. log transform for an exponential relationship).\n",
    "- **Remove Noise.** Linear regression assumes that your input and output variables are not noisy. Consider using data cleaning operations that let you better expose and clarify the signal in your data. This is most important for the output variable and you want to remove outliers in the output variable (y) if possible.\n",
    "- **Remove Collinearity.** Linear regression will over-fit your data when you have highly correlated input variables. Consider calculating pairwise correlations for your input data and removing the most correlated.\n",
    "- **Gaussian Distributions.** Linear regression will make more reliable predictions if your input and output variables have a Gaussian distribution. You may get some benefit using transforms (e.g. log or BoxCox) on you variables to make their distribution more Gaussian looking.\n",
    "- **Rescale Inputs:** Linear regression will often make more reliable predictions if you rescale input variables using standardization or normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae7498a-f531-4eeb-b85a-eeae4e4a6ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('std_scalar', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_test = pipeline.transform(X_test)\n",
    "TEST = pipeline.fit_transform(TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99464b82-38fc-47be-822e-e564fb1afd92",
   "metadata": {},
   "source": [
    "## ✔️ Regression Evaluation Metrics\n",
    "\n",
    "\n",
    "Here are three common evaluation metrics for regression problems:\n",
    "\n",
    "> - **Mean Absolute Error** (MAE) is the mean of the absolute value of the errors:\n",
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n",
    "\n",
    "> - **Mean Squared Error** (MSE) is the mean of the squared errors:\n",
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "> - **Root Mean Squared Error** (RMSE) is the square root of the mean of the squared errors:\n",
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$\n",
    "\n",
    "> - **Residuals** (R2):\n",
    "\n",
    "> 📌 Comparing these metrics:\n",
    "- **MAE** is the easiest to understand, because it's the average error.\n",
    "- **MSE** is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world.\n",
    "- **RMSE** is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
    "- **R2** is independent of each other, independent of x, normally distributed, common variance, have 0 mean\n",
    "\n",
    "> All of these are **loss functions**, because we want to minimize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb91bd74-2d1a-482c-a842-8188ac7fa102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def print_evaluate(true, predicted):  \n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    print('MAE:', mae)\n",
    "    print('MSE:', mse)\n",
    "    print('RMSE:', rmse)\n",
    "    print('R2 Square', r2_square)\n",
    "    print('__________________________________')\n",
    "    \n",
    "def evaluate(true, predicted):\n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    return mae, mse, rmse, r2_square"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f253e2-7b37-457a-a246-0b3df8a23bef",
   "metadata": {},
   "source": [
    "# 📈 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff80949-e0b5-4461-97a8-d0df19d4cd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression(normalize=True)\n",
    "lin_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66886510-b9a0-46ce-9e6e-1a47cf220626",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Evaluate coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522760d1-641c-4b6d-a881-0a9f0596235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the intercept\n",
    "print(lin_reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd34e89-1d9c-40aa-b911-92abb316b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(lin_reg.coef_, X.columns, columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c08c92-00c6-454a-9204-a64ce3d270dc",
   "metadata": {},
   "source": [
    "> Interpreting the coefficients:\n",
    "- Holding all other features fixed, a 1 unit increase in **Distance(mi)** is associated with an **increase of \\0.087860**.\n",
    "- Holding all other features fixed, a 1 unit increase in **Temperature(F)** is associated with an **decrease of \\-0.014064**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e76bfc-331a-4472-a10b-96105c5fc303",
   "metadata": {},
   "source": [
    "## ✔️ Predictions from our Model\n",
    "\n",
    "Let's grab predictions off our test set and see how well it did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d780164-80fa-4f49-b877-8c0f747801ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pred = lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f46539f-c393-4a48-981d-4a0b7c9cb999",
   "metadata": {},
   "source": [
    "**Residual Histogram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd563d-5e14-4e9a-877d-6df22746d3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_pred = lin_reg.predict(X_test)\n",
    "train_pred = lin_reg.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ecb7fb-65de-43a1-afd5-e6ed06ccd925",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(data=[[\"Linear Regression\", *evaluate(y_test, test_pred)]],\n",
    "                          columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb09c327-7f32-4327-8a97-36a0eb25353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "\n",
    "plt.plot(test_pred, label='Predicted', color='pink')\n",
    "plt.plot(y_test, label='Actual')\n",
    "\n",
    "plt.ylabel('Severity')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29435183-aea3-4033-a480-893e4116a0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "y_predict_model_lin_reg = lin_reg.predict(TEST)\n",
    "\n",
    "output = pd.DataFrame({\"ID\": accident_ID, \"Severity\": y_predict_model_lin_reg})\n",
    "\n",
    "output.to_csv('submission_lin_reg.csv', index=False)\n",
    "print(\"Submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74aeda-fbb4-4570-b07b-96badc1f75ea",
   "metadata": {},
   "source": [
    "# Regularization Techniques\n",
    "\n",
    "* Linear regression works by selecting coefficients for each independent variable that minimizes a loss function. However, if the coefficients are too large, it can lead to model over-fitting on the training dataset. Such a model will not generalize well on the unseen data. To overcome this shortcoming, we do regularization which penalizes large coefficients. The following are the regularization algorithms.\n",
    "\n",
    "#### Pros of Regularization\n",
    "\n",
    "--> We can use a regularized model to reduce the dimensionality of the training dataset. Dimensionality reduction is important because of three main reasons:\n",
    "\n",
    "--> Prevents Overfitting: A high-dimensional dataset having too many features can sometimes lead to overfitting (model captures both real and random effects).\n",
    "\n",
    "--> Simplicity: An over-complex model having too many features can be hard to interpret especially when features are correlated with each other.\n",
    "\n",
    "--> Computational Efficiency: A model trained on a lower dimensional dataset is computationally efficient (execution of algorithm requires less computational time).\n",
    "\n",
    "\n",
    "#### Cons of Regularization\n",
    "\n",
    "--> Regularization leads to dimensionality reduction, which means the machine learning model is built using a lower dimensional dataset. This generally leads to a high bias errror.\n",
    "\n",
    "--> If regularization is performed before training the model, a perfect balance between bias-variance tradeoff must be used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f4330c-2b58-4e63-910c-45f4c89e3101",
   "metadata": {},
   "source": [
    "# 📈 Ridge Regression\n",
    "\n",
    "> Source: [scikit-learn](http://scikit-learn.org/stable/modules/linear_model.html#ridge-regression)\n",
    "\n",
    "> Ridge regression addresses some of the problems of **Ordinary Least Squares** by imposing a penalty on the size of coefficients. The ridge coefficients minimize a penalized residual sum of squares,\n",
    "\n",
    "$$\\min_{w}\\big|\\big|Xw-y\\big|\\big|^2_2+\\alpha\\big|\\big|w\\big|\\big|^2_2$$\n",
    "\n",
    "> $\\alpha>=0$ is a complexity parameter that controls the amount of shrinkage: the larger the value of $\\alpha$, the greater the amount of shrinkage and thus the coefficients become more robust to collinearity.\n",
    "\n",
    "> Ridge regression is an L2 penalized model. Add the squared sum of the weights to the least-squares cost function.\n",
    "***\n",
    "\n",
    "#### Pros\n",
    "\n",
    "--> Avoids overfitting a model.\n",
    "\n",
    "--> The ridge estimator is preferably good at improving the least-squares estimate when there is multicollinearity.\n",
    "\n",
    "\n",
    "#### Cons\n",
    "\n",
    "--> They include all the predictors in the final model.\n",
    "\n",
    "--> They are unable to perform feature selection.\n",
    "\n",
    "--> They shrink the coefficients towards zero.\n",
    "\n",
    "--> They trade the variance for bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef2b957-1946-41a3-b346-cce58d17744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Ridge(alpha=100, solver='cholesky', tol=0.0001, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "train_pred = model.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dee9eb-02d5-4676-ada1-7537fc0cecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"Ridge Regression\", *evaluate(y_test, test_pred)]],\n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1f90af-b0da-4756-be3c-60663da8e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "\n",
    "plt.plot(test_pred, label='Predicted', color='pink')\n",
    "plt.plot(y_test, label='Actual')\n",
    "\n",
    "plt.ylabel('Severity')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8395fe85-c32b-43b8-9326-2d3b1fa72529",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "y_predict_Ridge = model.predict(TEST)\n",
    "\n",
    "output = pd.DataFrame({\"ID\": accident_ID, \"Severity\": y_predict_Ridge})\n",
    "\n",
    "output.to_csv('submission_Ridge.csv', index=False)\n",
    "print(\"Submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4ef544-ee8e-4700-af73-4d8d60eb4ed9",
   "metadata": {},
   "source": [
    "# 📈 Ridge Regression\n",
    "\n",
    " LASSO Regression\n",
    "\n",
    "> A linear model that estimates sparse coefficients.\n",
    "\n",
    "> Mathematically, it consists of a linear model trained with $\\ell_1$ prior as regularizer. The objective function to minimize is:\n",
    "\n",
    "$$\\min_{w}\\frac{1}{2n_{samples}} \\big|\\big|Xw - y\\big|\\big|_2^2 + \\alpha \\big|\\big|w\\big|\\big|_1$$\n",
    "\n",
    "> The lasso estimate thus solves the minimization of the least-squares penalty with $\\alpha \\big|\\big|w\\big|\\big|_1$ added, where $\\alpha$ is a constant and $\\big|\\big|w\\big|\\big|_1$ is the $\\ell_1-norm$ of the parameter vector.\n",
    "***\n",
    "\n",
    "#### Pros\n",
    "\n",
    "--> Avoids overfitting a model.\n",
    "\n",
    "--> The ridge estimator is preferably good at improving the least-squares estimate when there is multicollinearity.\n",
    "\n",
    "\n",
    "#### Cons\n",
    "\n",
    "--> They include all the predictors in the final model.\n",
    "\n",
    "--> They are unable to perform feature selection.\n",
    "\n",
    "--> They shrink the coefficients towards zero.\n",
    "\n",
    "--> They trade the variance for bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e28971-765a-4eae-b2b5-dc1f6b458c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model = Lasso(alpha=0.1, \n",
    "              precompute=True, \n",
    "              positive=True, \n",
    "              selection='random',\n",
    "              random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "train_pred = model.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abb82eb-f566-4e39-abae-bc495ed745a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"Lasso Regression\", *evaluate(y_test, test_pred)]],\n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aa8eb6-641f-4138-9594-46534ff6c1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "\n",
    "plt.plot(test_pred, label='Predicted', color='pink')\n",
    "plt.plot(y_test, label='Actual')\n",
    "\n",
    "plt.ylabel('Severity')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cbe2e5-7d6a-4759-ae19-d33b9759f32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "y_predict_Lasso = model.predict(TEST)\n",
    "\n",
    "output = pd.DataFrame({\"ID\": accident_ID, \"Severity\": y_predict_Lasso})\n",
    "\n",
    "output.to_csv('submission_lasso.csv', index=False)\n",
    "print(\"Submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbee9417-d248-4501-bcf2-e1e45f09ed4e",
   "metadata": {},
   "source": [
    "# 📈 Ridge Regression\n",
    "\n",
    "Elastic Net\n",
    "\n",
    "> A linear regression model trained with L1 and L2 prior as regularizer. \n",
    "\n",
    "> This combination allows for learning a sparse model where few of the weights are non-zero like Lasso, while still maintaining the regularization properties of Ridge. \n",
    "\n",
    "> Elastic-net is useful when there are multiple features which are correlated with one another. Lasso is likely to pick one of these at random, while elastic-net is likely to pick both.\n",
    "\n",
    "> A practical advantage of trading-off between Lasso and Ridge is it allows Elastic-Net to inherit some of Ridge’s stability under rotation.\n",
    "\n",
    "> The objective function to minimize is in this case\n",
    "\n",
    "$$\\min_{w}{\\frac{1}{2n_{samples}} \\big|\\big|X w - y\\big|\\big|_2 ^ 2 + \\alpha \\rho \\big|\\big|w\\big|\\big|_1 +\n",
    "\\frac{\\alpha(1-\\rho)}{2} \\big|\\big|w\\big|\\big|_2 ^ 2}$$\n",
    "***\n",
    "\n",
    "#### Pros\n",
    "--> Doesn’t have the problem of selecting more than n predictors when n<<p, whereas LASSO saturates when n<<p.\n",
    "\n",
    "#### Cons\n",
    "--> Computationally more expensive than LASSO or Ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e762882-1533-463b-a0ec-a3c1f6cbe5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "model = ElasticNet(alpha=0.1, l1_ratio=0.9, selection='random', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "train_pred = model.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1893ea58-a1d1-453b-a8b0-77dae3da783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"Elastic Net Regression\", *evaluate(y_test, test_pred)]],\n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c466a8-cf04-4373-923c-320910de6115",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "y_predict_ElasticNet = model.predict(TEST)\n",
    "\n",
    "output = pd.DataFrame({\"ID\": accident_ID, \"Severity\": y_predict_ElasticNet})\n",
    "\n",
    "output.to_csv('submission_ElasticNet.csv', index=False)\n",
    "print(\"Submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2b6d9f-99f0-487b-9395-be061894fefb",
   "metadata": {},
   "source": [
    "#  📈 Polynomial Regression\n",
    "> Source: [scikit-learn](http://scikit-learn.org/stable/modules/linear_model.html#polynomial-regression-extending-linear-models-with-basis-functions)\n",
    "\n",
    "***\n",
    "\n",
    "> One common pattern within machine learning is to use linear models trained on nonlinear functions of the data. This approach maintains the generally fast performance of linear methods, while allowing them to fit a much wider range of data.\n",
    "\n",
    "> For example, a simple linear regression can be extended by constructing polynomial features from the coefficients. In the standard linear regression case, you might have a model that looks like this for two-dimensional data:\n",
    "\n",
    "$$\\hat{y}(w, x) = w_0 + w_1 x_1 + w_2 x_2$$\n",
    "\n",
    "> If we want to fit a paraboloid to the data instead of a plane, we can combine the features in second-order polynomials, so that the model looks like this:\n",
    "\n",
    "$$\\hat{y}(w, x) = w_0 + w_1 x_1 + w_2 x_2 + w_3 x_1 x_2 + w_4 x_1^2 + w_5 x_2^2$$\n",
    "\n",
    "> The (sometimes surprising) observation is that this is still a linear model: to see this, imagine creating a new variable\n",
    "\n",
    "$$z = [x_1, x_2, x_1 x_2, x_1^2, x_2^2]$$\n",
    "\n",
    "> With this re-labeling of the data, our problem can be written\n",
    "\n",
    "$$\\hat{y}(w, x) = w_0 + w_1 z_1 + w_2 z_2 + w_3 z_3 + w_4 z_4 + w_5 z_5$$\n",
    "\n",
    "> We see that the resulting polynomial regression is in the same class of linear models we’d considered above (i.e. the model is linear in w) and can be solved by the same techniques. By considering linear fits within a higher-dimensional space built with these basis functions, the model has the flexibility to fit a much broader range of data.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdbfdf7-c746-4675-a64f-22641f95835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_reg = PolynomialFeatures(degree=2)\n",
    "\n",
    "X_train_2_d = poly_reg.fit_transform(X_train)\n",
    "X_test_2_d = poly_reg.transform(X_test)\n",
    "TEST_2d = poly_reg.fit_transform(TEST)\n",
    "\n",
    "lin_reg = LinearRegression(normalize=True)\n",
    "lin_reg.fit(X_train_2_d,y_train)\n",
    "\n",
    "test_pred = lin_reg.predict(X_test_2_d)\n",
    "train_pred = lin_reg.predict(X_train_2_d)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08581325-73ac-48ea-a3fc-dba4194f084b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"Polynomial Regression\", *evaluate(y_test, test_pred)]],\n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c87641-3b1b-4b2b-8022-93965107cef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "\n",
    "plt.plot(test_pred, label='Predicted', color='pink')\n",
    "plt.plot(y_test, label='Actual')\n",
    "\n",
    "plt.ylabel('Severity')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ea57bc-ebc2-468f-b7c3-ed056a5e6763",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "y_predict_poly_reg = lin_reg.predict(TEST_2d)\n",
    "\n",
    "output = pd.DataFrame()\n",
    "output['ID'] = accident_ID\n",
    "output['Severity'] = y_predict_poly_reg\n",
    "\n",
    "output.to_csv('submission_poly_reg.csv', index=False)\n",
    "print(\"Submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22efeac-5287-40b9-8ff8-22199e2a5c7c",
   "metadata": {},
   "source": [
    "# 📈 Stochastic Gradient Descent\n",
    "\n",
    "> Gradient Descent is a very generic optimization algorithm capable of finding optimal solutions to a wide range of problems. The general idea of Gradient Sescent is to tweak parameters iteratively in order to minimize a cost function. Gradient Descent measures the local gradient of the error function with regards to the parameters vector, and it goes in the direction of descending gradient. Once the gradient is zero, you have reached a minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c0cf56-1f8a-4a40-b742-b8447c7ca89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_reg = SGDRegressor(n_iter_no_change=250, penalty=None, eta0=0.0001, max_iter=100000)\n",
    "sgd_reg.fit(X_train, y_train)\n",
    "\n",
    "test_pred = sgd_reg.predict(X_test)\n",
    "train_pred = sgd_reg.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e96fe2-7fe9-47b5-9c67-dcbd1da555da",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"Stochastic Gradient Descent\", *evaluate(y_test, test_pred), 0]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf9abe7-ca4a-4bac-bd78-454a3ba739a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "\n",
    "plt.plot(test_pred, label='Predicted', color='pink')\n",
    "plt.plot(y_test, label='Actual')\n",
    "\n",
    "plt.ylabel('Severity')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99ea8c6-3d1b-4ed0-a616-bd31f4da359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "y_predict_poly_sgd_reg = sgd_reg.predict(TEST)\n",
    "\n",
    "output = pd.DataFrame({\"ID\": accident_ID, \"Severity\": y_predict_poly_sgd_reg})\n",
    "\n",
    "output.to_csv('submission_sgd_reg.csv', index=False)\n",
    "print(\"Submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "033b9660-503e-4872-9af9-894cc60817a8",
   "metadata": {},
   "source": [
    "# 📈 Artficial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf944c7-eb56-4334-8158-09b8d211494d",
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Install a pip package in the current Jupyter kernel\n",
    "!{sys.executable} -m pip install tensorflow\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=Adam(0.00001), loss='mse')\n",
    "\n",
    "r = model.fit(X_train, y_train,\n",
    "              validation_data=(X_test,y_test),\n",
    "              batch_size=1,\n",
    "              epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548e85bd-750a-4ba0-87be-5aba5bb44123",
   "metadata": {},
   "source": [
    "**---->OBSERVATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67459e8-bca0-475a-9304-1be641d7d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "train_pred = model.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa1a6b9-76ba-4cec-a918-99f481011b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"Artificial Neural Network\", *evaluate(y_test, test_pred), 0]],\n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45774256-c01d-4849-b03f-888e60e6f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "\n",
    "plt.plot(test_pred, label='Predicted', color='pink')\n",
    "plt.plot(y_test, label='Actual')\n",
    "\n",
    "plt.ylabel('Severity')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e237b2-456b-4857-8652-9fc9da77882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_model_arti = model.predict(TEST)\n",
    "\n",
    "output = pd.DataFrame()\n",
    "output['ID'] = accident_ID\n",
    "output['Severity'] = y_predict_model_arti\n",
    "\n",
    "output.to_csv('submission_arti.csv', index=False)\n",
    "print(\"Submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3e95e2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### -----------> OBSERVATION\n",
    "\n",
    "<hr>\n",
    "\n",
    "A comparison between multiple linear regression model and the model produced by the ANN is presented in tables\n",
    "above ,it can be seen that the ANN model has better predictive power than regression model\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e80f375-b935-46b7-99c5-8b49bade50f5",
   "metadata": {},
   "source": [
    "# 📈 Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58c8be0-e45f-4b44-bf1a-af614efbb535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation:\n",
      "_____________________________________\n",
      "MAE: 0.29837193099058046\n",
      "MSE: 0.24750842612349494\n",
      "RMSE: 0.49750218705398164\n",
      "R2 Square 0.33470745103136834\n",
      "__________________________________\n",
      "Train set evaluation:\n",
      "_____________________________________\n",
      "MAE: 0.11509929772514248\n",
      "MSE: 0.037120792333790044\n",
      "RMSE: 0.19266756949157282\n",
      "R2 Square 0.9009313490252006\n",
      "__________________________________\n",
      "Wall time: 39min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators=1000)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "test_pred = rf_reg.predict(X_test)\n",
    "train_pred = rf_reg.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a42172-8daf-4598-8db5-8ea2becf5a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                         Model       MAE       MSE      RMSE  R2 Square  \\\n0            Linear Regression  0.389231  0.332648  0.576757   0.105855   \n1             Ridge Regression  0.389242  0.332647  0.576756   0.105858   \n2             Lasso Regression  0.430157  0.369314  0.607712   0.007299   \n3       Elastic Net Regression  0.418849  0.355361  0.596121   0.044805   \n4        Polynomial Regression  0.377467  0.313703  0.560092   0.156779   \n5  Stochastic Gradient Descent  0.389215  0.332647  0.576755   0.105859   \n6    Artificial Neural Network  2.230520  5.353064  2.313669 -13.388818   \n7      Random Forest Regressor  0.298372  0.247508  0.497502   0.334707   \n\n   Cross Validation  \n0         -0.165365  \n1         -0.165364  \n2         -0.304343  \n3         -0.321694  \n4          0.000000  \n5          0.000000  \n6          0.000000  \n7          0.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>MAE</th>\n      <th>MSE</th>\n      <th>RMSE</th>\n      <th>R2 Square</th>\n      <th>Cross Validation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Linear Regression</td>\n      <td>0.389231</td>\n      <td>0.332648</td>\n      <td>0.576757</td>\n      <td>0.105855</td>\n      <td>-0.165365</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ridge Regression</td>\n      <td>0.389242</td>\n      <td>0.332647</td>\n      <td>0.576756</td>\n      <td>0.105858</td>\n      <td>-0.165364</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Lasso Regression</td>\n      <td>0.430157</td>\n      <td>0.369314</td>\n      <td>0.607712</td>\n      <td>0.007299</td>\n      <td>-0.304343</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Elastic Net Regression</td>\n      <td>0.418849</td>\n      <td>0.355361</td>\n      <td>0.596121</td>\n      <td>0.044805</td>\n      <td>-0.321694</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Polynomial Regression</td>\n      <td>0.377467</td>\n      <td>0.313703</td>\n      <td>0.560092</td>\n      <td>0.156779</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Stochastic Gradient Descent</td>\n      <td>0.389215</td>\n      <td>0.332647</td>\n      <td>0.576755</td>\n      <td>0.105859</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Artificial Neural Network</td>\n      <td>2.230520</td>\n      <td>5.353064</td>\n      <td>2.313669</td>\n      <td>-13.388818</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Random Forest Regressor</td>\n      <td>0.298372</td>\n      <td>0.247508</td>\n      <td>0.497502</td>\n      <td>0.334707</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"Random Forest Regressor\", *evaluate(y_test, test_pred), 0]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1ede9b-de28-40ce-a9e8-fbba172a9a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1440x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "\n",
    "plt.plot(test_pred, label='Predicted', color='pink')\n",
    "plt.plot(y_test, label='Actual')\n",
    "\n",
    "plt.ylabel('Severity')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ab23bf-2930-4ff0-8a4e-0de8493be196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "y_predict_rf_reg = rf_reg.predict(TEST)\n",
    "\n",
    "output = pd.DataFrame()\n",
    "output['ID'] = accident_ID\n",
    "output['Severity'] = y_predict_rf_reg\n",
    "\n",
    "output.to_csv('submission_rf_reg.csv', index=False)\n",
    "print(\"Submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bc39df-b88f-48b1-9161-5f92a0612015",
   "metadata": {},
   "source": [
    "# 📊 Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec3c033-5e94-41f7-9669-b3bd45258669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:ylabel='Model'>"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 864x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df.set_index('Model', inplace=True)\n",
    "results_df['R2 Square'].plot(kind='barh', figsize=(12, 8), color='pink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b04310bc-440e-4484-8349-6e85c37bdf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "#\n",
    "# # Save the model as a pickle in a file\n",
    "# joblib.dump(lin_reg, 'lin_reg.pkl')\n",
    "# joblib.dump(model, 'arti.pkl')\n",
    "# joblib.dump(rf_reg, 'RandomForest.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fad9ee6-e958-4035-8f8c-38bd1931527c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"color:#ffc0cb;font-size:40px;font-family:Georgia;text-align:center;\"><strong>📝 5. Summary</strong></h1>\n",
    "\n",
    "In this notebook, I discovered the linear regression algorithm for machine learning, including:\n",
    "> - The standard linear regression models (Ridge, Lasso, ElasticNet, ...).\n",
    "> - The representation used by the model.\n",
    "> - Learning algorithms are used to estimate the coefficients in the model.\n",
    "> - Rules of thumb to consider when preparing data for use with linear regression.\n",
    "> - How to evaluate a linear regression model.\n",
    "+ The number of unique cities where accidents have taken place in the USA: 10658\n",
    "+ The Top 5 cities of USA with the maximum number of accidents in 4 years are: Los Angeles, Miami, Charlotte, Houston, Dallas\n",
    "+ The percentage of cities that have more than 1000 accidents in a year is: 2.3552594538800786%\n",
    "+ 1167 cities of USA have had only an accident in 4 years!\n",
    "+ The maximum number of accidents have taken place at around 4-5P.M. which can be a result of the fact that most people are traveling back to their homes after work which causes a rush hour.\n",
    "+ Surprisingly, the maximum number of accidents occurred on a Thursday and not on the weekend. This means that maybe, not many people travel on the weekends\n",
    "+ Los Angeles is the City with the highest number of accidents in the USA (2016-2020)\n",
    "+ Miami is the City with the second-highest number of accidents in the USA (2016-2020)\n",
    "+ California is the State with the highest number of accidents in the USA (2016-2020)\n",
    "+ Florida is the State with the second-highest number of accidents in the USA (2016-2020)\n",
    "+ In 80% of Cases of road accidents, the impact on the traffic was Moderate - 2\n",
    "+ In 10% of Cases of road accidents, the impact on the traffic was Severe - 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa45f08-358a-4f53-a295-21dd6a9b787e",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "<h1 style=\"color:#ffc0cb;font-size:40px;font-family:Georgia;text-align:center;\"><strong>6. References</strong></h1>\n",
    "\n",
    "+ Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, and Rajiv Ramnath. [“A Countrywide Traffic Accident Dataset.”](https://arxiv.org/abs/1906.05409), arXiv preprint arXiv:1906.05409 (2019). Access Nov 27, 2021.\n",
    "\n",
    "+ Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, Radu Teodorescu, and Rajiv Ramnath. [“Accident Risk Prediction based on Heterogeneous Sparse Data: New Dataset and Insights.”](https://arxiv.org/abs/1909.09638) In proceedings of the 27th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM, 2019. Access Nov 27, 2021.\n",
    "\n",
    "+ Sobhan Moosavi, Mohammad Hossein Samavatian, Arnab Nandi, Srinivasan\n",
    "Parthasarathy, and Rajiv Ramnath. 2019. Short and Long-term Pattern Discovery\n",
    "Over Large-Scale Geo-Spatiotemporal Data. In Proceedings of the 25th ACM\n",
    "SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM. Access Dec 2, 2021.\n",
    "\n",
    "### ANN model:\n",
    "\n",
    "+ M. Çodur and A. Tortum, \"An Artificial Neural Network Model for Highway Accident Prediction: A Case Study of Erzurum, Turkey\", PROMET - Traffic&Transportation, vol. 27, no. 3, pp. 217-225, 2015. Available: 10.7307/ptt.v27i3.1551 [Accessed 18 December 2021].\n",
    "\n",
    "+ A. Alqatawna, A. Rivas Álvarez and S. García-Moreno, \"Comparison of Multivariate Regression Models and Artificial Neural Networks for Prediction Highway Traffic Accidents in Spain: A Case Study\", Transportation Research Procedia, vol. 58, pp. 277-284, 2021. Available: 10.1016/j.trpro.2021.11.038 [Accessed 18 December 2021].\n",
    "\n",
    "+ M. Ghasedi, M. Sarfjoo and I. Bargegol, \"Prediction and Analysis of the Severity and Number of Suburban Accidents Using Logit Model, Factor Analysis and Machine Learning: A case study in a developing country\", SN Applied Sciences, vol. 3, no. 1, 2021. Available: 10.1007/s42452-020-04081-3 [Accessed 19 December 2021]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a643814-d498-4274-968c-d70c51641038",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "<h1 style=\"color:#ffc0cb;font-size:40px;font-family:Georgia;text-align:center;\"><strong>7. Appendix</strong></h1>\n",
    "\n",
    "Extra models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932890fe-96e9-487b-8128-3f67fd2c0551",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}